<?xml version="1.0" encoding="UTF-8" ?>
<Document corpusVersion="3" name="A17_M09_Motion_Graphs">
  
    314cdb4ffe999411ffe446ddb3cfdf25d59e148dce001ad40723a3406bd5b5cb
    3y2s
    http://dx.doi.org/10.2172/7134495
  
  
    
      
        <article-title>Motion Graphs</article-title>
      
      To appear in Proceedings of SIGGRAPH ’02
      
        
          Lucas Kovar Michael Gleicher ∗ Frédéric Pighin † University of Wisconsin-Madison University of Wisconsin-Madison University of Southern California Institute for Creative Technologies
          ∗
        
      
      ∗ e-mail: {kovar,gleicher}@cs.wisc.edu † e-mail: pighin@ict.usc.edu
      
        
      
      <Sentence ann2="DRI_Outcome_Contribution" agreement="3diff" ann1="Sentence" ann3="DRI_Challenge_Goal">In this paper we present a novel method for creating realistic, controllable motion.</Sentence> <DRI_Approach agreement="All_Equal">Given a corpus of motion capture data, we automatically construct a directed graph called a motion graph that encapsulates connections among the database.</DRI_Approach> <DRI_Approach agreement="All_Equal">The motion graph consists both of pieces of original motion and automatically generated transitions.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Approach">Motion can be generated simply by building walks on the graph.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">We present a general framework for extracting particular graph walks that meet a user’s specifications.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">We then show how this framework can be applied to the specific problem of generating different styles of locomotion along arbitrary paths.</DRI_Outcome>
	<h2>CR Categories: </h2> I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism <h2>Keywords: </h2>motion synthesis, motion capture, animation with constraints
    
    
      
        <h1>1 Introduction</h1>
      
      <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">Realistic human motion is an important part of media like video games and movies.</DRI_Background> <DRI_Challenge ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">More lifelike characters make for more immersive environments and more believable special effects.</DRI_Challenge> <DRI_Challenge ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">At the same time, realistic animation of human motion is a challenging task, as people have proven to be adept at discerning the subtleties of human movement and identifying inaccuracies.</DRI_Challenge> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">One common solution to this problem is motion capture.</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">However, while motion capture is a reliable way of acquiring realistic human motion, by itself it is a technique for reproducing motion.</DRI_Background> <DRI_Challenge agreement="All_Equal">Motion capture data has proven to be difficult to modify, and editing techniques are reliable only for small changes to a motion.</DRI_Challenge> <DRI_Challenge agreement="All_Equal">This limits the utility of motion capture  if the data on hand isn’t sufficiently similar to what is desired, then often there is little that can be done other than acquire more data, a time-consuming and expensive process.</DRI_Challenge> <DRI_Challenge agreement="All_Equal">This in particular is a problem for applications that require motion to be synthesized dynamically, such as interactive environments.</DRI_Challenge> <DRI_Challenge_Goal agreement="All_Equal">Our goal is to retain the realism of motion capture while also giving a user the ability to control and direct a character.</DRI_Challenge_Goal> <DRI_Challenge_Goal agreement="All_Equal">For example, we would like to be able to ask a character to walk around a room without worrying about having a piece of motion data that contains the correct number of steps and travels in the right directions.</DRI_Challenge_Goal> <DRI_Challenge_Goal ann2="DRI_Approach" agreement="3diff" ann1="DRI_Challenge_Goal" ann3="DRI_Challenge">We also need to be able to direct characters who can perform multiple actions, rather than those who are only capable of walking around.</DRI_Challenge_Goal> <DRI_Outcome_Contribution agreement="All_Equal">This paper presents a method for synthesizing streams of motions based on a corpus of captured movement while preserving the quality of the original data.</DRI_Outcome_Contribution> <DRI_Approach agreement="All_Equal">Given a set of motion capture data, we compile a structure called a motion graph that encodes how the captured clips may be re-assembled in different ways.</DRI_Approach> <DRI_Approach agreement="All_Equal">The motion graph is a directed graph wherein edges contain either pieces of original motion data or automatically generated transitions.</DRI_Approach> <DRI_Approach agreement="All_Equal">The nodes then serve as choice points where these small bits of motion join seamlessly.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome_Contribution">Because our methods automatically detect and create transitions between motions, users needn’t capture motions specifically designed to connect to one another.</DRI_Approach> <DRI_Approach agreement="All_Equal">If desired, the user can tune the high-level structure of the motion graph to produce desired degrees of connectivity among different parts.</DRI_Approach> <DRI_Approach agreement="All_Equal">Motion graphs transform the motion synthesis problem into one of selecting sequences of nodes, or graph walks.</DRI_Approach> <DRI_Approach agreement="All_Equal">By drawing upon algorithms from graph theory and AI planning, we can extract graph walks that satisfy certain properties, thereby giving us control over the synthesized motions.</DRI_Approach> <DRI_Approach agreement="All_Equal">To demonstrate the potential of our approach, we introduce a simple example.</DRI_Approach> <DRI_Approach agreement="All_Equal">We were donated 78.5 seconds of motion capture, or about 2400 frames of animation, of a performer randomly walking around with both sharp and smooth turns.</DRI_Approach> <DRI_Approach agreement="All_Equal">Since the motion was donated, we did not carefully plan out each movement, as the literature suggests is critical to successful application of motion capture data [Washburn 2001].</DRI_Approach> <DRI_Approach agreement="All_Equal">From this data we constructed a motion graph and used an algorithm described later in this paper to extract motions that travelled along paths sketched on the ground.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Characteristic movements of the original data like sharp turns were automatically used when appropriate, as seen in Figure 1 .</DRI_Approach> <DRI_Approach agreement="All_Equal">It is possible to place additional constraints on the desired motion.</DRI_Approach> <DRI_Approach ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">For example, we noticed that part of the motion had the character sneaking around.</DRI_Approach> <DRI_Approach ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">By labelling these frames as special, we were able to specify that at certain points along the path the character must only use sneaking movements, and at other parts of the motion it must use normal walking motions, as is also shown in Figure 1 .</DRI_Approach> <DRI_Unspecified agreement="All_Equal">The remainder of this paper is organized as follows.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">In Section 2 we describe related work.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">In Section 3 we describe how a motion graph is constructed from a database of motion capture.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">In Section 4 we set forth a general framework for extracting motion from the motion graph that meets user specifications.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">Section 5 discusses the specific problem of generating movements along a path and how it is handled in our framework.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">We conclude in Section 6 with a discussion of the scalability of our approach to large data sets and potential future work.</DRI_Unspecified>
      1
      To appear in Proceedings of SIGGRAPH ’02
      
        
        Figure 1: The top images show original motion capture data; two are walking motions and one is a sneaking motion. The black curves show the paths travelled by the character. The bottom images show new motion generated by a motion graph built out of these examples plus their mirror images. Images 1 and 2 show the result of having the motion graph fit walking motion to the smooth yellow paths. The black curve is the actual position of the center of mass on each frame. Image 3 shows motion formed by having the character switch from walking to sneaking halfway down the path.
      
      
        <h1>2 Related Work</h1>
        <DRI_Background agreement="All_Equal">Much previous work with motion capture has revolved around editing individual clips of motion.</DRI_Background> <DRI_Background agreement="All_Equal">Motion warping [Witkin and Popović 1995] can be used to smoothly add small changes to a motion.</DRI_Background> <DRI_Background agreement="All_Equal">Retargeting [Gleicher 1998; Lee and Shin 1999] maps the motion of a performer to a character of different proportions while retaining important constraints like footplants.</DRI_Background> <DRI_Background agreement="All_Equal">Various signal processing operations [Bruderlin and Williams 1995] can be applied to motion data.</DRI_Background> <DRI_Outcome_Contribution ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome_Contribution">Our work is different from these efforts in that it involves creating continuous streams of motion, rather than modifying specific clips.</DRI_Outcome_Contribution> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">One strategy for motion synthesis is to perform multi-target blends among a set of examples, yielding a continuous space of parameterized motion.</DRI_Background> <DRI_Background agreement="All_Equal">Wiley and Hahn [1997] used linear interpolation to create parameterizations of walking at various inclinations and reaching to various locations.</DRI_Background> <DRI_Background agreement="All_Equal">Rose et al. [1998] used radial basis functions to blend among clips representing the same motion performed in different styles.</DRI_Background> <DRI_Background ann2="DRI_Approach" agreement="3diff" ann1="DRI_Background" ann3="DRI_Challenge_Goal">These works have a focus complementary to ours: while they are mainly concerned with generating parameterizations of individual clips, we are concerned with constructing controllable sequences of clips.</DRI_Background> <DRI_Background agreement="All_Equal">Another popular approach to motion synthesis is to construct statistical models.</DRI_Background> <DRI_Background agreement="All_Equal">Pullen and Bregler [2000] used kernel-based probability distributions to synthesize new motion based on the statistical properties of example motion.</DRI_Background> <DRI_Background agreement="All_Equal">Coherency was added to the model by explicitly accounting for correlations between parameters.</DRI_Background> <DRI_Background agreement="All_Equal">Bowden [2000], Galata et al. [2001], and Brand and Hertzmann [2000] all processed motion capture data by constructing abstract “states” which each represent entire sets of poses.</DRI_Background> <DRI_Background agreement="All_Equal">Transition probabilities between states were used to drive motion synthesis.</DRI_Background> <DRI_Background agreement="All_Equal">Since these statistical models synthesize motion based on abstractions of data rather than actual data, they risk losing important detail.</DRI_Background> <DRI_Outcome_Contribution ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome_Contribution">In our work we have tighter guarantees on the quality of generated motion.</DRI_Outcome_Contribution> <DRI_Background agreement="All_Equal">Moreover, these systems did not focus on the satisfaction of high-level constraints.</DRI_Background> <DRI_Approach agreement="All_Equal">We generate motion by piecing together example motions from a database.</DRI_Approach> <DRI_Background agreement="All_Equal">Numerous other researchers have pursued similar strategies.</DRI_Background> <DRI_Background agreement="All_Equal">Perlin [1995] and Perlin and Goldberg [1996] used a rulebased system and simple blends to attach procedurally generated motion into coherent streams.</DRI_Background> <DRI_Background agreement="All_Equal">Faloutsos et al. [2001] used support vector machines to create motion sequences as compositions of actions generated from a set of physically based controllers.</DRI_Background> <DRI_Approach agreement="All_Equal">Since our system involves motion capture data, rather than procedural or physically based motion, we require different approaches to identifying and generating transitions.</DRI_Approach> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Challenge_Goal">Also, these systems were mainly concerned with appropriately generating individual transitions, whereas we address the problem of generating entire motions (with many transitions) that meet user-specified criteria.</DRI_Background> <DRI_Background agreement="All_Equal">Lamouret and van de Panne [1996] developed a system that used a database to extract motion meeting high-level constraints.</DRI_Background> <DRI_Background agreement="All_Equal">However, their system was applied to a simple agent with five degrees of freedom, whereas we generate motion for a far more sophisticated character.</DRI_Background> <DRI_Background agreement="All_Equal">Molina-Tanco and Hilton [2000] used a state-based statistical model similar to those mentioned in the previous paragraph to rearrange segments of original motion data.</DRI_Background> <DRI_Background agreement="All_Equal">These segments were attached using linear interpolation.</DRI_Background> <DRI_Background agreement="All_Equal">The user could create motion by selecting keyframe poses, which were connected with a highprobability sequence of states.</DRI_Background> <DRI_Approach agreement="All_Equal">Our work considers more general and sophisticated sets of constraints.</DRI_Approach> <DRI_Background agreement="All_Equal">Work similar to ours has been done in the gaming industry to meet the requirements of online motion generation.</DRI_Background> <DRI_Background agreement="All_Equal">Many companies use move trees [Mizuguchi et al. 2001], which (like motion graphs) are graph structures representing connections in a database of motion.</DRI_Background> <DRI_Background agreement="All_Equal">However, move trees are created manually — short motion clips are collected in carefully scripted capture sessions and blends are created by hand using interactive tools.</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Motion graphs are constructed automatically.</DRI_Background> <DRI_Background agreement="All_Equal">Also, move trees are typically geared for rudimentary motion planning (“I want to turn left, so I should follow this transition”), as opposed to more complicated objectives.</DRI_Background> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">The generation of transitions is an important part of our approach.</DRI_Approach> <DRI_Background agreement="All_Equal">Early work in this area was done by Perlin [1995], who presented a simple method for smoothly interpolating between two clips to create a blend.</DRI_Background> <DRI_Background agreement="All_Equal">Lee [2000] defined orientation filters that allowed these blending operations to be performed on rotational data in a more principled fashion.</DRI_Background> <DRI_Background agreement="All_Equal">Rose et al. [1996] presented a more complex method for creating transitions that preserved kinematic constraints and basic dynamic properties.</DRI_Background> <DRI_Outcome ann2="DRI_Approach" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Challenge_Goal">Our main application of motion graphs is to control a character’s locomotion.</DRI_Outcome> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">This problem is important enough to have received a great deal of prior attention.</DRI_Background> <DRI_Challenge ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">Because a character’s path isn’t generally known in advance, synthesis is required.</DRI_Challenge> <DRI_Background agreement="All_Equal">Procedural and physically based synthesis methods have been developed for a few activities such as walking [Multon et al. 1999; Sun and Metaxas 2001] and running [Hodgins et al. 1995; Bruderlin and Calvert 1996].</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">While techniques such as these can generate flexible motion paths, the current range of movement styles is limited.</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">Also, these methods do not produce the quality of motion attainable by hand animation or motion capture.</DRI_Background> <DRI_Background agreement="All_Equal">While Gleicher [2001] presented a method for editing the path traversed in a clip of motion capture, it did not address the need for continuous streams of motion, nor could it choose which clip is correct to fit a path (e.g. that a turning motion is better when we have a curved path).</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Our basic approach — detecting transitions, constructing a graph, and using graph search techniques to find sequences satisfying user demands — has been applied previously to other problems.</DRI_Approach> <DRI_Background agreement="All_Equal">Schödl et al. [2000] developed a similar method for synthesizing seamless streams of video from example footage and driving these streams according to high-level user input.</DRI_Background> <DRI_Background agreement="All_Equal">Since writing this paper, we have learned of similar work done concurrently by a number of research groups.</DRI_Background> <DRI_Background agreement="All_Equal">Arikan and Forsythe [2002] constructed from a motion database a hierarchical graph similar to ours and used a randomized search algorithm to extract motion that meets user constraints.</DRI_Background> <DRI_Background agreement="All_Equal">Lee et al. [2002] also constructed a graph and generated motion via three user interfaces: a list of choices, a sketch-based interface similar to what we use for path fitting (Section 5), and a live video feed.</DRI_Background> <DRI_Background agreement="All_Equal">Pullen and Bregler [2002] keyframed a subset of a character’s degrees of freedom and matched small segments of this keyframed animation with the lower frequency bands of motion data.</DRI_Background> <DRI_Background agreement="All_Equal">This resulted in sequences of short clips forming complete motions.</DRI_Background> <DRI_Background agreement="All_Equal">Li et al [2002] generated a two-level statistical model of motion.</DRI_Background> <DRI_Background agreement="All_Equal">At the lower level were linear dynamic systems representing characteristic movements called “textons”, and the higher level contained transition probabilities among textons.</DRI_Background> <DRI_Background agreement="All_Equal">This model was used both to generate new motion based on user keyframes and to edit existing motion.</DRI_Background>
        2
        To appear in Proceedings of SIGGRAPH ’02
      
      
        <h1>3 Motion Graph Construction</h1>
        <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">In this section, we define the motion graph structure and the procedure for constructing it from a database of clips.</DRI_Unspecified> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">A clip of motion is defined as a regular sampling of the character’s parameters, which consist of the position of the root joint and quaternions representing the orientations of each joint.</DRI_Approach> <Sentence agreement="All_Equal">We</Sentence>
        
          Figure 2: Consider a motion graph built from two initial clips. (top) We can trivially
        
        <Sentence agreement="All_Equal">insert a node to divide an initial clip into two smaller clips.</Sentence> <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Unspecified">(bottom) We can also insert a transition joining either two different initial clips or different parts of the same initial clip.</Sentence>
        <Sentence agreement="All_Equal">also allow clips (or, more generally, sets of frames) to be annotated with other information, such as descriptive labels (“walking,” “karate”) and constraint information (left heel must be planted on these frames).</Sentence> <DRI_Approach agreement="All_Equal">A motion graph is a directed graph where all edges correspond to clips of motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">Nodes serve as choice points connecting these clips, i.e., each outgoing edge is potentially the successor to any incoming edge.</DRI_Approach> <DRI_Approach agreement="All_Equal">A trivial motion graph can be created by placing all the initial clips from the database as arcs in the graph.</DRI_Approach> <DRI_Approach agreement="All_Equal">This creates a disconnected graph with 2n nodes, one at the beginning and end of each clip.</DRI_Approach> <DRI_Approach agreement="All_Equal">Similarly, an initial clip can be broken into two clips by inserting a node, since the later part of the motion is a valid successor to the earlier part (see Figure 2 ).</DRI_Approach> <DRI_Approach agreement="All_Equal">A more interesting graph requires greater connectivity.</DRI_Approach> <DRI_Approach agreement="All_Equal">For a node to have multiple outgoing edges, there must be multiple clips that can follow the clip(s) leading into the node.</DRI_Approach> <DRI_Approach agreement="All_Equal">Since it is unlikely that two pieces of original data are sufficiently similar, we need to create clips expressly for this purpose.</DRI_Approach> <DRI_Approach agreement="All_Equal">Transitions are clips designed such that they can seamlessly connect two segments of original data.</DRI_Approach> <DRI_Approach agreement="All_Equal">By introducing nodes within the initial clips and inserting transition clips between otherwise disconnected nodes, we can create a wellconnected structure with a wide range of possible graph walks (see Figure 2 ).</DRI_Approach> <DRI_Approach agreement="All_Equal">Unfortunately, creating transitions is a hard animation problem.</DRI_Approach> <DRI_Approach agreement="All_Equal">Imagine, for example, creating a transition between a run and a backflip.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">In real life this would require several seconds for an athlete to perform, and the transition motion looks little like the motions it connects.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Challenge">Hence the problem of automatically creating such a transition is arguably as difficult as that of creating realistic motion in the first place.</DRI_Approach> <DRI_Approach agreement="All_Equal">On the other hand, if two motions are “close” to each other then simple blending techniques can reliably generate a transition.</DRI_Approach> <DRI_Approach agreement="All_Equal">In light of this, our strategy is to identify portions of the initial clips that are sufficiently similar that straightforward blending is almost certain to produce valid transitions.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">The remainder of this section is divided into three parts.</DRI_Unspecified> <DRI_Unspecified ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Approach">First we describe our algorithm for detecting a set of candidate transition points.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">In the following two sections we discuss how we select among these candidate transitions and how blends are created at the chosen transition points.</DRI_Unspecified> <DRI_Unspecified ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Approach">Finally, we explain how to prune the graph to eliminate problematic edges.</DRI_Unspecified>
        3
        To appear in Proceedings of SIGGRAPH ’02
      
      
        <h1>3.1 Detecting Candidate Transitions</h1>
        <DRI_Approach agreement="All_Equal">As in our system, motion capture data is typically represented as vectors of parameters specifying the root position and joint rotations of a skeleton on each frame.</DRI_Approach> <DRI_Approach agreement="All_Equal">One might attempt to locate transition points by computing some vector norm to measure the difference between poses at each pair of frames.</DRI_Approach> <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Approach" ann3="Sentence">However, such a simple approach is ill-advised, as it fails to address a number of important issues:
        1.</Sentence> <DRI_Approach agreement="All_Equal">Simple vector norms fail to account for the meanings of the parameters.</DRI_Approach> <DRI_Approach agreement="All_Equal">Specifically, in the joint angle representation some parameters have a much greater overall effect on the character than others (e.g., hip orientation vs. wrist orientation).</DRI_Approach> <DRI_Approach agreement="All_Equal">Moreover, there is no meaningful way to assign fixed weights to these parameters, as the effect of a joint rotation on the shape of the body depends on the current configuration of the body.</DRI_Approach> <DRI_Unspecified ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">2.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">A motion is defined only up to a rigid 2D coordinate transformation.</DRI_Approach> <DRI_Approach agreement="All_Equal">That is, the motion is fundamentally unchanged if we translate it along the floor plane or rotate it about the vertical axis.</DRI_Approach> <DRI_Approach agreement="All_Equal">Hence comparing two motions requires identifying compatible coordinate systems.</DRI_Approach> <DRI_Unspecified ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">3.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">Smooth blends require more information than can be obtained at individual frames.</DRI_Approach> <DRI_Approach agreement="All_Equal">A seamless transition must account not only for differences in body posture, but also in joint velocities, accelerations, and possibly higher-order derivatives.</DRI_Approach>
        <DRI_Approach agreement="All_Equal">Our similarity metric incorporates each of these considerations.</DRI_Approach> <DRI_Approach agreement="All_Equal">To motivate it, we note that the skeleton is only a means to an end.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">In a typical animation, a polygonal mesh is deformed according to the skeleton’s pose.</DRI_Approach> <DRI_Approach agreement="All_Equal">This mesh is all that is seen, and hence it is a natural focus when considering how close two frames of animation are to each other.</DRI_Approach> <DRI_Approach agreement="All_Equal">For this reason we measure the distance between two frames of animation in terms of a point cloud driven by the skeleton.</DRI_Approach> <DRI_Approach agreement="All_Equal">Ideally this point cloud is a downsampling of the mesh defining the character.</DRI_Approach>     <DRI_Approach agreement="All_Equal">To calculate the distance D( i , ¡ j ) between two frames i and ¡ j , we consider the point clouds formed over two windows of frames of user-defined length k, one bordered at the beginning by   i and the other bordered at the end by ¡ j .</DRI_Approach> <DRI_Approach agreement="All_Equal">That is, each point cloud is the composition of smaller point clouds representing the pose at each frame in the window.</DRI_Approach> <DRI_Approach agreement="All_Equal">The use of windows of frames effectively incorporates derivative information into the metric, and is similar to the approach in [Schödl et al. 2000].</DRI_Approach> <DRI_Approach agreement="All_Equal">The size of the   windows are the same as the length of the transitions, so D( i , ¡ j ) is affected by every pair of frames that form the transition.</DRI_Approach> <Sentence agreement="All_Equal">We use a value of k corresponding to a window of about a third of a second in length, as in [Mizuguchi et al. 2001]   The distance between i and ¡ j may be calculated by computing a weighted sum of squared distances between corresponding points p i and p i in the two point clouds.</Sentence> <DRI_Approach agreement="All_Equal">To address the problem of finding coordinate systems for these point clouds (item 2 in the above list), we calculate the minimal weighted sum of squared distances given that an arbitrary rigid 2D transformation may be applied to the second point cloud:</DRI_Approach>
        
          1
          θ min ,x ,z ∑ i w i p i − T θ ,x 0 ,z 0 p i 2
        
        <Sentence agreement="All_Equal">where the linear transformation T θ ,x 0 ,z 0 rotates a point p about the y (vertical) axis by θ degrees and then translates it by (x 0 , z 0 ).</Sentence> <Sentence agreement="All_Equal">The</Sentence>
        
          
          Figure 3: An example error function for two motions. The entry at (i, j) contains the error for making a transition from the i th frame of the first motion to the j th frame of
        
        <Sentence agreement="All_Equal">the second.</Sentence> <DRI_Unspecified ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">White values correspond to lower errors and black values to higher errors.</DRI_Unspecified> <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">The colored dots represent local minima.</DRI_Unspecified>
        <Sentence agreement="All_Equal">index is over the number of points in each point cloud.</Sentence> <DRI_Approach agreement="All_Equal">The weights w i may be chosen both to assign more importance to certain joints (e.g., those with constraints) and to taper off towards the end of the window.</DRI_Approach> <DRI_Approach agreement="All_Equal">This optimization has a closed-form solution:</DRI_Approach>
        
          2
          θ = arctan ∑ ∑ i i w w i i (x (x i i z x i i − + x z i i z z i i ) ) − − ∑ ∑ i i 1 1 w w i i (xz (xx − + x zz z) )
        
        
          3
          1 x 0 = ∑ w (x − x cos( θ ) − z sin θ )
        
        
          4
          1 z 0 = ∑ w (z + x sin( θ ) − z cos θ )
        
        <Sentence agreement="All_Equal">where x = ∑ i w i x i and the other barred terms are defined similarly.</Sentence> <DRI_Approach agreement="All_Equal">We compute the distance as defined above for every pair of frames in the database, forming a sampled 2D error function.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Figure 3 shows a typical result.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">To make our transition model more compact, we find all the local minima of this error function, thereby extracting the “sweet spots” at which transitions are locally the most opportune.</DRI_Approach> <DRI_Background agreement="All_Equal">This tactic was also used in [Schödl et al. 2000].</DRI_Background> <DRI_Approach agreement="All_Equal">These local minima are our candidate transition points.</DRI_Approach>
      
      
        <h1>3.2 Selecting Transition Points</h1>
        <DRI_Approach agreement="All_Equal">A local minimum in the distance function does not necessarily imply a high-quality transition; it only implies a transition better than its neighbors.</DRI_Approach> <DRI_Approach agreement="All_Equal">We are specifically interested in local minima with small error values.</DRI_Approach> <DRI_Approach agreement="All_Equal">The simplest approach is to only accept local minima below an empirically determined threshold.</DRI_Approach> <DRI_Approach agreement="All_Equal">This can be done without user intervention.</DRI_Approach> <DRI_Approach agreement="All_Equal">However, often users will want to set the threshold themselves to pick an acceptable tradeoff between having good transitions (low threshold) and having high connectivity (high threshold).</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Approach">Different kinds of motions have different fidelity requirements.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Approach">For example, walking motions have very exacting requirements on the transitions — people have seen others walk nearly every day since birth and consequently have a keen sense of what a walk should look like.</DRI_Approach> <DRI_Challenge ann2="DRI_Approach" agreement="3diff" ann1="DRI_Challenge" ann3="DRI_Background">On the other hand, most people are less familiar with ballet motions and would be less likely to detect inaccuracies in such motion.</DRI_Challenge> <DRI_Approach agreement="All_Equal">As a result, we allow a user to apply different thresholds to different pairs of motions; transitions among ballet motions may have a higher acceptance threshold than transitions among walking motions.</DRI_Approach>
        4
        To appear in Proceedings of SIGGRAPH ’02
      
      
        <h1>3.3 Creating Transitions</h1>
          <DRI_Approach agreement="All_Equal">If D( i , ¡ j ) meets the threshold requirements, we create a tran    sition by blending frames i to i+k−1 with frames ¡ j−k+1 to ¡ j , inclusive.</DRI_Approach> <DRI_Approach agreement="All_Equal">The first step is to apply the appropriate aligning 2D transformation to motion .</DRI_Approach> <DRI_Approach agreement="All_Equal">Then on frame p of the transition ¡ (0 ≤ p &lt; k) we linearly interpolate the root positions and perform spherical linear interpolation on joint rotations:</DRI_Approach>
        
          5
          R p = α (p)R + [1 − α (p)]R i+p j−k+1+p
        
        
          6
          q ip = sler p(q i ¢ , q i £ , α (p)) i+p j−k+1+p
        
        <Sentence agreement="All_Equal">where R p is the root position on the p th transition frame and q ip is the rotation of the i th joint on the p th transition frame.</Sentence> <DRI_Approach agreement="All_Equal">To maintain continuity we choose the blend weights α (p) according to the conditions that α (p) = 1 for p ≤ −1, α (p) = 0 for p ≥ k, and that α (p) has C 1 continuity everywhere.</DRI_Approach> <Sentence agreement="All_Equal">This requires</Sentence>
        
          7
          α (p) = 2( p + 1 ) 3 − 3( p + 1 ) 2 + 1, −1 &lt; p &lt; k k k
        
        <DRI_Background ann2="DRI_Approach" agreement="3diff" ann1="DRI_Background" ann3="Sentence">Other transition schemes, such as [Rose et al. 1996], may be used in place of this one.</DRI_Background> <DRI_Approach agreement="All_Equal">The use of linear blends means that constraints in the original motion may be violated.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, one of the character’s feet may slide when it ought to be planted.</DRI_Approach> <DRI_Approach agreement="All_Equal">This can be corrected by using constraint annotations in the original motions.</DRI_Approach> <DRI_Approach agreement="All_Equal">We treat constraints as binary signals: on a given frame a particular constraint either exists or it does not.</DRI_Approach> <DRI_Approach agreement="All_Equal">Blending these signals in analogy to equations 5   and 6 amounts to using the constraints from in the first half of the transition and the constraints from in the second half.</DRI_Approach> <DRI_Approach agreement="All_Equal">In this ¡ manner each transition is automatically annotated with constraint information, and these constraints may later be enforced as a postprocessing step when motion is extracted form the graph.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">We will discuss constraint enforcement in more detail in the next section.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">Descriptive labels attached to the motions are carried along into transitions.</DRI_Approach> <DRI_Approach agreement="All_Equal">Specifically, if a transition frame is a blend between a frame with a set of labels L 1 and another frame with a set of labels L 2 , then it has the union of these labels L 1 ∪ L 2 .</DRI_Approach>
        1 2 3 4 5 6 7 8
        
          Figure 4: A simple motion graph. The largest strongly connected component is [1, 2, 3, 6, 7, 8]. Node 4 is a sink and 5 is a dead end.
        
      
      
        <h1>3.4 Pruning The Graph</h1>
        <DRI_Approach agreement="All_Equal">In its current state there are no guarantees that the graph can synthesize motion indefinitely, since there may be nodes (called dead ends) that are not part of any cycle (see Figure 4 ).</DRI_Approach> <DRI_Approach agreement="All_Equal">Once such a node is entered there is a bound on how much additional motion can be generated.</DRI_Approach> <DRI_Approach agreement="All_Equal">Other nodes (called sinks) may be part of one or more cycles but nonetheless only be able to reach a small fraction of the total number of nodes in the graph.</DRI_Approach> <DRI_Approach agreement="All_Equal">While arbitrarily long motion may still be generated once a sink is entered, this motion is confined to a small part of the database.</DRI_Approach> <DRI_Approach agreement="All_Equal">Finally, some nodes may have incoming edges such that no outgoing edges contain the same set of descriptive labels.</DRI_Approach> <DRI_Approach agreement="All_Equal">This is dangerous since logical discontinuities may be forced into a motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, a character currently in a “boxing” motion may have no choice but to transition to a “ballet” motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">To address these problems, we prune the graph such that, starting from any edge, it is possible to generate arbitrarily long streams of motion of the same type such that as much of the database as possible is used.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Unspecified">This is done as follows.</DRI_Approach> <DRI_Approach agreement="All_Equal">Every frame of original data is associated with a (possibly empty) set of labels.</DRI_Approach> <DRI_Approach agreement="All_Equal">Say there are n unique sets.</DRI_Approach> <DRI_Approach agreement="All_Equal">For each set, form the subgraph consisting of all edges whose frames have exactly this set of labels.</DRI_Approach> <DRI_Approach agreement="All_Equal">Compute the strongly connected components (SCCs) of this subgraph, where an SCC is a maximal set of nodes such that there is a connecting graph walk for any ordered pair of nodes (u, v).</DRI_Approach> <DRI_Approach agreement="All_Equal">The SCCs can be computed in O(V + E) time using an algorithm due to Tarjan.</DRI_Approach> <DRI_Approach agreement="All_Equal">We eliminate from this subgraph (and hence the original motion graph) any edge that does not attach two nodes in the largest SCC.</DRI_Approach> <DRI_Approach agreement="All_Equal">Once this process is completed for all n label sets, any nodes with no edges are discarded.</DRI_Approach> <DRI_Approach agreement="All_Equal">A warning is given to the user if the largest SCC for a given set of labels contains below a threshold number of frames.</DRI_Approach> <DRI_Approach agreement="All_Equal">Also, a warning is given if for any ordered pair of SCCs there is no way to transition from the first to the second.</DRI_Approach> <DRI_Approach agreement="All_Equal">In either case, the user may wish to adjust the transition thresholds (Section 3.2) to give the graph greater connectivity.</DRI_Approach>
      
      
        <h1>4 Extracting Motion</h1>
        <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Unspecified">By this stage we have finished constructing the motion graph.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Unspecified">After describing exactly how a graph walk can be converted into displayable motion, we will consider the general problem of extracting motion that satisfies user constraints.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Unspecified">Our algorithm involves solving an optimization problem, and so we conclude this section with some general recommendations on how to pose the optimization.</DRI_Approach>
        5
        To appear in Proceedings of SIGGRAPH ’02
      
      
        <h1>4.1 Converting Graph Walks To Motion</h1>
        <DRI_Approach agreement="All_Equal">Since every edge on the motion graph is a piece of motion, a graph walk corresponds to a motion generated by placing these pieces one after another.</DRI_Approach> <DRI_Approach agreement="All_Equal">The only issue is to place each piece in the correct location and orientation.</DRI_Approach> <DRI_Approach agreement="All_Equal">In other words, each frame must be transformed by an appropriate 2D rigid transformation.</DRI_Approach> <DRI_Approach agreement="All_Equal">At the start of a graph walk this transformation is the identity.</DRI_Approach> <DRI_Approach agreement="All_Equal">Whenever we exit a transition edge, the current transformation is multiplied by the transformation that aligned the pieces of motion connected by the transition (Section 3.1).</DRI_Approach> <DRI_Approach agreement="All_Equal">As noted in Section 3.3, the use of linear blends to create transitions can cause artifacts, the most common of which is feet that slide when they ought to be planted.</DRI_Approach> <DRI_Approach agreement="All_Equal">However, every graph walk is automatically annotated with constraint information (such as that the foot must be planted).</DRI_Approach> <DRI_Approach agreement="All_Equal">These constraints are either specified directly in the original motions or generated as in Section 3.3, depending on whether the frame is original data or a transition.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Approach">These constraints may be satisfied using a variety of methods, such as [Gleicher 1998] or [Lee and Shin 1999].</DRI_Approach> <DRI_Approach agreement="All_Equal">In our work we used the method described in [Kovar et al. 2002].</DRI_Approach>
      
      
        <h1>4.2 Searching For Motion</h1>
        <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Approach">We are now in a position to consider the problem of finding motion that satisfies user-specified requirements.</DRI_Approach> <DRI_Approach agreement="All_Equal">It is worth first noting that only very special graph walks are likely to be useful.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, while a random graph walk will generate a continuous stream of motion, such an algorithm has little use other than an elaborate screen saver.</DRI_Approach> <DRI_Approach agreement="All_Equal">As a more detailed example, consider computing an all-pairs shortest graph walk table for the graph.</DRI_Approach> <DRI_Approach agreement="All_Equal">That is, given a suitable metric — say, time elapsed or distance travelled — we can use standard graph algorithms like Floyd-Warshall to find for each pair of nodes u and v the connecting graph walk that minimizes the metric.</DRI_Approach> <DRI_Approach agreement="All_Equal">With this in hand we could, for example, generate the motion that connects one clip to another as quickly as possible.</DRI_Approach> <DRI_Approach agreement="All_Equal">This is less useful than it might appear at first.</DRI_Approach> <DRI_Approach agreement="All_Equal">First, there are no guarantees that the shortest graph walk is short in an absolute sense.</DRI_Approach> <DRI_Approach agreement="All_Equal">In our larger test graphs (between a few and several thousand nodes) the average shortest path between any two nodes was on the order of two seconds.</DRI_Approach> <DRI_Approach agreement="All_Equal">This is not because the graphs were poorly connected.</DRI_Approach> <DRI_Approach agreement="All_Equal">Since the transitions were about one-third of a second apiece, this means there were on average only five or six transitions separating any two of the thousands of nodes.</DRI_Approach> <DRI_Approach agreement="All_Equal">Second, there is no control over what happens during the graph walk — we can’t specify what direction the character travels in or where she ends up.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Approach">More generally, the sorts of motions that a user is likely to be interested in probably don’t involve minimizing metrics as simple as total elapsed time.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Approach">However, for complicated metrics there is typically no simple way of finding the globally optimal graph walk.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge_Goal" ann3="DRI_Approach">Hence we focus instead on local search methods that try to find a satisfactory graph walk within a reasonable amount of time.</DRI_Approach> <DRI_Challenge_Goal ann2="DRI_Approach" agreement="3diff" ann1="DRI_Challenge_Goal" ann3="DRI_Unspecified">We now present our framework for extracting graph walks that conform to a user’s specifications.</DRI_Challenge_Goal> <DRI_Approach agreement="All_Equal">We cast motion extraction as a search problem and use branch and bound to increase the efficiency of this search.</DRI_Approach> <DRI_Approach agreement="All_Equal">The user supplies a scalar function g(w, e) that evaluates the additional error accrued by appending an edge e to the existing path w, which may be the empty path 0.</DRI_Approach> <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Unspecified">/ The total error f (w) of the path is defined as follows:</Sentence>
        
          8
          n f (w) = f ([e 1 , . . . , e n ]) = ∑ g([e 1 , . . . , e i−1 ], e i ) i=1
        
        <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="Sentence">where w is comprised of the edges e 1 , . . . , e n .</Sentence> <DRI_Approach agreement="All_Equal">We require g(w, e) to be nonnegative, which means that we can never decrease the total error by adding more edges to a graph walk.</DRI_Approach> <DRI_Approach agreement="All_Equal">In addition to f and g, the user must also supply a halting condition indicating when no additional edges should be added to a graph walk.</DRI_Approach> <DRI_Approach agreement="All_Equal">A graph walk satisfying the halting condition is called complete.</DRI_Approach> <DRI_Approach agreement="All_Equal">The start of the graph walk may either be specified by the user or chosen at random.</DRI_Approach> <DRI_Approach agreement="All_Equal">Our goal is find a complete graph walk w that minimizes f .</DRI_Approach> <DRI_Approach agreement="All_Equal">To give the user control over what sorts of motions should be considered in the search, we allow restrictions on what edges may be appended to a given walk w.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, the user may decide that within a particular window of time a graph walk may only contain “sneaking” edges.</DRI_Approach> <DRI_Approach agreement="All_Equal">A naıve solution is to use depth-first search to evaluate f for all complete graph walks and then select the best one.</DRI_Approach> <DRI_Approach agreement="All_Equal">However, the number of possible graph walks grows exponentially with the average size of a complete graph walk.</DRI_Approach> <DRI_Approach agreement="All_Equal">To address this we use a branch and bound strategy to cull branches of the search that are incapable of yielding a minimum.</DRI_Approach> <DRI_Approach agreement="All_Equal">Since g(w, e) by assumption never decreases, f (w) is a lower bound on f (w + v) for any v, where w + v is the graph walk composed of v appended to w.</DRI_Approach> <DRI_Approach agreement="All_Equal">Thus we can keep track of the current best complete graph walk w opt and immediately halt any branch of the search for which the graph walk’s error exceeds f (w opt ).</DRI_Approach> <DRI_Approach agreement="All_Equal">Also, the user may define a threshold error ε such that if f (w) &lt; ε , then w is considered to be “good enough” and the search is halted.</DRI_Approach> <DRI_Approach agreement="All_Equal">Branch and bound is most successful when we can attain a tight lower bound early in the search process.</DRI_Approach> <DRI_Approach agreement="All_Equal">For this reason it is worthwhile to have a heuristic for ordering the edges we explore out of a particular node.</DRI_Approach> <DRI_Approach agreement="All_Equal">One simple heuristic is to order the children greedily — that is, given a set of unexplored children c 1 , . . . , c n , we search the one that minimizes g(w, c i ).</DRI_Approach> <DRI_Approach agreement="All_Equal">While branch and bound reduces the number of graph walks we have to test against f , it does not change the fact that the search process is inherently exponential — it merely lowers the effective branching factor.</DRI_Approach> <DRI_Approach agreement="All_Equal">For this reason we generate a graph walk incrementally.</DRI_Approach> <DRI_Approach agreement="All_Equal">At each step we use branch and bound to find an optimal graph walk of n frames.</DRI_Approach> <DRI_Approach agreement="All_Equal">We retain the first m frames of this graph walk and use the final retained node as a starting point for another search.</DRI_Approach> <DRI_Approach agreement="All_Equal">This process continues until a complete graph walk is generated.</DRI_Approach> <DRI_Approach agreement="All_Equal">In our implementation we used values of n from 80 to 120 frames (2 3 2 to 4 seconds) and m from 25 to 30 frames (about one second).</DRI_Approach> <DRI_Approach agreement="All_Equal">Sometimes it is useful to have a degree of randomness in the search process, such as when one is animating a crowd.</DRI_Approach> <DRI_Approach agreement="All_Equal">There are a couple of easy ways to add randomness to the search process without sacrificing a good result.</DRI_Approach> <DRI_Approach agreement="All_Equal">The first is to select a start for the search at random.</DRI_Approach> <DRI_Approach agreement="All_Equal">The second is retain the r best graph walks at the end of each iteration of the search and randomly pick among the ones whose error is within some tolerance of the best solution.</DRI_Approach>
      
      
        <h1>4.3 Deciding What To Ask For</h1>
        <DRI_Approach agreement="All_Equal">Since the motion extracted from the graph is determined by the function g, it is worth considering what sorts of functions are likely to produce desirable results.</DRI_Approach> <DRI_Approach agreement="All_Equal">To understand the issues involved, we consider a simple example.</DRI_Approach> <DRI_Approach agreement="All_Equal">Imagine we want to lay down two clips on the floor and create a motion that starts at the first clip and ends at the second.</DRI_Approach> <DRI_Approach agreement="All_Equal">Both clips must end up in the specified position and orientation.</DRI_Approach> <Sentence ann2="DRI_Approach" agreement="3diff" ann1="Sentence" ann3="DRI_Unspecified">We can formally state this problem as follows: given a starting node N in the graph and a target edge e, find a graph walk this section.</Sentence> <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">The halting condition was to play a specific clip of two kicking motions.</DRI_Unspecified> <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">The error of a complete graph walk (which necessarily ended with the kicking clip) was determined by how far away this kicking clip was from being in a particular position and orientation.</DRI_Unspecified> <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">The character spends approximately seven seconds making minute adjustments to its orientation in an attempt to better align itself with the final clip.</DRI_Unspecified> <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">The highlighted line shows the the path of the target clip in its desired position and orientation.</DRI_Unspecified> <Sentence ann2="DRI_Approach" agreement="2equal_1diff" ann1="Sentence" ann3="Sentence">that ends with e such that the transformation T applied to e is as close as possible to a given transformation T .</Sentence> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">What one will receive is a motion like in Figure 5 , where the initial clip is a walking motion and the final clip is a kick.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">The character turns around in place several times in an attempt to better line up with the target clip.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">While it’s conceivable that given a larger database we would have found a better motion, the problem here is with the function we passed into the search algorithm.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">First, it gives no guidance as to what should be done in the middle of the motion; all that matters is that the final clip be in the right position and orientation.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">This means the character is allowed to do whatever is possible in order to make the final fit, even if the motion is nothing that a real person would do.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">Second, the goal is probably more specific than necessary.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">If it doesn’t matter what kick the character does, then it should be allowed to choose a kick that doesn’t require such effort to aim.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">More generally, there are two lessons we can draw from this example.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">First, g should give some sort of guidance throughout the entire motion, as arbitrary motion is almost never desirable.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Second, g should be no more restrictive than necessary, in order to give the search algorithm more goals to seek.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Note the tradeoff here — guiding the search toward a particular result must be balanced against unduly preventing it from considering all available options.</DRI_Outcome>
        6
        To appear in Proceedings of SIGGRAPH ’02
        
          
          Figure 5: The above motion was generated using the search algorithm discussed in
        
      
      
        <h1>5 Path Synthesis</h1>
        <DRI_Approach agreement="All_Equal">We have cast motion extraction as an optimization problem, and we have given some reasons why the formulation of this optimization can be difficult.</DRI_Approach> <DRI_Approach agreement="All_Equal">To demonstrate that it is nonetheless possible to come up with optimization criteria that allow us to solve a real problem, we apply the preceding framework to path synthesis.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="Sentence">This problem is simple to state: given a path P specified by the user, generate motion such that the character travels along P. In this section we present our algorithm for path synthesis, present results, and discuss applications of the technique.</DRI_Approach>
      
      
        <h1>5.1 Implementing Path Synthesis</h1>
        <DRI_Approach agreement="All_Equal">Given the framework in the previous section, our only tasks are to define an error function g(w, e) and appropriate halting criteria.</DRI_Approach> <Sentence agreement="All_Equal">The basic idea is to estimate the actual path P travelled by the character during a graph walk and measure how different it is from P. The graph walk is complete when P is sufficiently long.</Sentence> <DRI_Approach agreement="All_Equal">A simple way to determine P is to project the root onto the floor at each frame, forming a piecewise linear curve 1 .</DRI_Approach> <DRI_Approach agreement="All_Equal">Let P(s) be the point on P whose arc-length distance from the start of P is s.</DRI_Approach> <DRI_Approach agreement="All_Equal">The i th frame of the graph walk, w i , is at some arc length s(w i ) from the start of P .</DRI_Approach> <DRI_Approach agreement="All_Equal">We define the corresponding point on P as the point at the same arc length, P(s(w i )).</DRI_Approach> <DRI_Approach agreement="All_Equal">For the j th frame of e, we calculate the squared distance between P (s(e j )) and P(s(e j )).</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Unspecified">g(w, e) is the sum of these errors:</DRI_Approach>
        
          9
          n g(w, e) = ∑ P (s(e i )) − P(s(e i )) 2 i=1
        
        <DRI_Approach agreement="All_Equal">Note that s(e i ) depends on the total arc length of w, which is why this equation is a function of w as well as e.</DRI_Approach> <Sentence agreement="All_Equal">The halting condition for path synthesis is when the current total length of P meets or exceeds that of P. Any frames on the graph walk at an arc length longer than the total length of P are mapped to the last point on P. The error function g(w, e) was chosen for a number of reasons.</Sentence> <DRI_Approach agreement="All_Equal">First, it is efficient to compute, which is important in making the search algorithm practical.</DRI_Approach> <DRI_Approach agreement="All_Equal">Second, the character is given incentive to make definite progress along the path.</DRI_Approach> <DRI_Approach agreement="All_Equal">If we were to have required the character to merely be near the path, then it would have no reason not to alternate between travelling forwards and backwards.</DRI_Approach> <DRI_Approach agreement="All_Equal">Finally, this metric allows the character to travel at whatever speed is appropriate for what needs to be done.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, a sharp turn will not cover distance at the same rate as walking straight forward.</DRI_Approach> <DRI_Approach agreement="All_Equal">Since both actions are equally important for accurate path synthesis, it is important that one not be given undue preference over the other.</DRI_Approach> <DRI_Approach agreement="All_Equal">One potential problem with this metric is that a character who stands still will never have an incentive to move forward, as it can accrue zero error by remaining in place.</DRI_Approach> <DRI_Approach agreement="All_Equal">While we have not encountered this particular problem in practice, it can be countered by requiring at least a small amount of forward progress γ on each frame.</DRI_Approach> <DRI_Approach agreement="All_Equal">More exactly, we can replace in Equation 9 the function s(e i ) with t(e i ) = max(t(e i−1 ) + s(e i ) − s(e i−1 ),t(e i−1 ) + γ ).</DRI_Approach> <DRI_Approach agreement="All_Equal">Typically the user will want all generated motion to be of a single type, such as walking.</DRI_Approach> <DRI_Approach agreement="All_Equal">This corresponds to confining the search to the subgraph containing the appropriate set of descriptive labels.</DRI_Approach> <DRI_Approach agreement="All_Equal">More interestingly, one can require different types of motion on different parts of the path.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, one might want the character to walk along the first half of the path and sneak down the rest.</DRI_Approach> <DRI_Approach agreement="All_Equal">The necessary modifications to accomplish this are simple.</DRI_Approach> <DRI_Approach agreement="All_Equal">We will consider the case of two different motion types; the generalization to higher numbers is trivial.</DRI_Approach> <DRI_Approach agreement="All_Equal">We divide the original path into two smaller adjoining paths, P 1 and P 2 , based on where the transition from type T 1 to type T 2 is to occur.</DRI_Approach> <DRI_Approach agreement="All_Equal">If the character is currently fitting P 2 , then the algorithm is identical to the single-type case.</DRI_Approach> <DRI_Approach agreement="All_Equal">If the character is fitting P 1 , then we check to see if we are a threshold distance from the end of P 1 .</DRI_Approach> <DRI_Approach agreement="All_Equal">If not, we continue to only consider edges of type T 1 .</DRI_Approach> <DRI_Approach agreement="All_Equal">Otherwise we allow the search to try both edges of type T 1 and T 2 ; in the latter case we switch to fitting P 2 .</DRI_Approach> <DRI_Approach agreement="All_Equal">Note that we only allow this switch to occur once on any given graph walk, which prevents the resulting motion from randomly switching between the two actions.</DRI_Approach>
      
      
        <h1>5.2 Results</h1>
        <DRI_Outcome agreement="All_Equal">While the examples shown in Figure 1 suggest that our technique is viable, it perhaps isn’t surprising that we were able to find accurate fits to the given paths.</DRI_Outcome> <Sentence agreement="All_Equal">As shown in the upper portion of the 1 In our implementation we defined the path as a spline approximating this piecewise linear path, although this has little impact on the results.</Sentence> <Sentence agreement="All_Equal">figure, the input motion had a fair amount of variation, including straight-ahead marches, sharp turns, and smooth changes of curvature.</Sentence> <DRI_Outcome agreement="All_Equal">However, our algorithm is still useful when the input database is not as rich.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">Refer to Figure 6 .</DRI_Unspecified> <DRI_Approach agreement="All_Equal">We started with a single 12.8second clip of an actor sneaking along the indicated path.</DRI_Approach> <DRI_Approach agreement="All_Equal">To stretch this data further, we created a mirror-image motion and then built a motion graph out of the two.</DRI_Approach> <DRI_Outcome agreement="All_Equal">From these we were able to construct the new motions shown at the bottom of the figure, both of which are themselves approximately 13 seconds in length.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">Figure 7 shows fits to a more complicated path.</DRI_Unspecified> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">The first example uses walking motions and the second uses martial arts motions; the latter demonstrates that our approach works even on motions that are not obviously locomotion.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">For the walking motion, the total computation time was nearly the same as the length of the generated animation (58.1 seconds of calculation for 54.9 seconds animation).</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">The martial arts motion is 87.7 seconds long and required just 15.0 seconds of computation.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">In general, in our test cases the duration of a generated motion was either greater than or approximately equal to the amount of time needed to produce it.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Both motion graphs had approximately 3000 frames (100 seconds) of animation.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">Finally, Figure 8 shows paths containing constraints on the allowable motion type.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">In the first section of each path the character is required to walk, in the second it must sneak, and in the third it is to perform martial arts moves.</DRI_Approach> <DRI_Outcome agreement="All_Equal">Not only does the character follow the path well, but transitions between action types occur quite close to their specified locations.</DRI_Outcome> <DRI_Approach agreement="All_Equal">This example used a database of approximately 6000 frames (200 seconds).</DRI_Approach> <DRI_Approach agreement="All_Equal">All examples were computed on a 1.3GHz Athlon.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">For our largest graph (about 6000 frames), approximately twenty-five minutes were needed to compute the locations of all candidate transitions points.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Approximately five minutes of user time were required to select transition thresholds, and it took less than a minute to calculate blends at these transitions and prune the resulting graph.</DRI_Outcome>
        7
        To appear in Proceedings of SIGGRAPH ’02
      
      
        <h1>5.3 Applications Of Path Synthesis</h1>
        <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">Directable locomotion is a general enough need that the preceding algorithm has many applications.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">Interactive Control.</DRI_Unspecified> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">We can use path synthesis techniques to give a user interactive control over a character.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">For example, when the user hits the left arrow key the character might start travelling east.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">To accomplish this, we can use the path fitting algorithm to find the sequence of edges starting from our current location on the graph that best allow the character to travel east.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">The first edge on the resulting graph walk is the next clip that will be played.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">This process may then be repeated.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="3diff" ann1="DRI_Outcome" ann3="Sentence">To make this practical, we can precompute for every node in the graph a sequence of graph walks that fit straight-line paths in a sampling of directions (0 degrees, 30 degrees, .</DRI_Outcome> . . <Sentence agreement="All_Equal">).</Sentence> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">The first edges on these paths are then stored for later use; they are the best edges to follow given the direction the character is supposed to travel in.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">High-Level Keyframing.</DRI_Unspecified> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">If we want a character to perform certain actions in a specific sequence and in specific locations, we can draw a path with subsections requiring the appropriate action types.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">This allows us to generate complex animations without the tedium of manual keyframing.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">For this reason we term this process “highlevel” keyframing — the user generates an animation based on what should be happening and where.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Motion Dumping.</DRI_Unspecified> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">If an AI algorithm is used to determine that a character must travel along a certain path or start performing certain actions, the motion graph may be used to “dump” motion on top of the algorithm’s result.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Hence motion graphs may be used as a back-end for animating non-player characters in video games and interactive environments — the paths and action types can be specified by a high-level process and the motion graph would fill in the details.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">Crowds.</DRI_Unspecified> <DRI_Outcome ann2="DRI_Approach" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Unspecified">While our discussion so far has focused on a single character, there’s no reason why it couldn’t be applied to several characters in parallel.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Motion graphs may be used as a practical tool for crowd generation.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">For example, a standard collision-avoidance algorithm could be used to generate a path for each individual, and the motion graph could then generate motion that conforms to this path.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Moreover, we can use the techniques described at the end of Section 4.2 to add randomness to the generated motion.</DRI_Outcome>
      
      
        <h1>6 Discussion</h1>
        <DRI_Outcome_Contribution agreement="All_Equal">In this paper we have presented a framework for generating realistic, controllable motion through a database of motion capture.</DRI_Outcome_Contribution> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Approach">Our approach involves automatically constructing a graph that encapsulates connections among different pieces of motion in the database and then searching this graph for motions that satisfy user constraints.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">We have applied our framework to the problem of path synthesis.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">As we had limited access to data, our largest examples used a database of several thousand frames of motion.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_FutureWork">While we believe this was sufficient to show the potential of our method, a character with a truly diverse set of actions might require hundreds or thousands of times more data.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Hence the scalability of our framework bears discussion.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Challenge">The principle computational bottleneck in graph construction is locating candidate transitions (Section 3.1).</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Challenge">This requires comparing every pair of the F frames in the database and therefore involves O(F 2 ) operations.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">However, this calculation is trivial to parallelize, and distances between old frames needn’t be recomputed if additions are made to the database.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">It is the exception rather than the rule that two pieces of motion are sufficiently similar that a transition is possible, and hence motion graphs tend to be sparse.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">In our experience the necessary amount of storage is approximately proportional to the size of the database.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">The number of edges leaving a node in general grows with the size of the graph, meaning the branching factor in our search algorithm may grow as well.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">However, we expect that future motion graphs will be larger mainly because the character will be able to perform more actions.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">That is, for example, having increasing amounts of walking motion isn’t particularly useful once one can direct a character along nearly any path.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Hence the branching factor in a particular subgraph will remain stationary once that subgraph is sufficiently large.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">We anticipate that typical graph searches will be restricted to one or two subgraphs, and so we expect that the search will remain practical even for larger graphs.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">We conclude with a brief discussion of future work.</DRI_Unspecified> <DRI_FutureWork ann2="DRI_FutureWork" agreement="2equal_1diff" ann1="DRI_FutureWork" ann3="DRI_Outcome">One limitation of our approach is that the transition thresholds must be specified by hand, since (as discussed in Section 3.2) different kinds of motions have different fidelity requirements.</DRI_FutureWork> <DRI_FutureWork agreement="All_Equal">Setting thresholds in databases involving many different kinds of motions may be overly laborious, and so we are investigating methods for automating this process.</DRI_FutureWork> <DRI_FutureWork agreement="All_Equal">A second area of future work is to incorporate parameterizable motions [Wiley and Hahn 1997; Rose et al. 1998] into our system, rather than having every node correspond to a static piece of motion.</DRI_FutureWork> <DRI_FutureWork agreement="All_Equal">This would add flexibility to the search process and potentially allow generated motion to better satisfy user constraints.</DRI_FutureWork> <DRI_FutureWork agreement="All_Equal">Finally, we are interested in applying motion graphs to problems other than path synthesis.</DRI_FutureWork>
        8
        To appear in Proceedings of SIGGRAPH ’02
        
          
          Figure 6: The leftmost image shows the original motion and its reflection and the following images show motion generated by our path synthesis algorithm. The thick yellow lines were the paths to be fit and the black line is an approximation of the actual path of the character. Note how we are able to accurately fit nontrivial paths despite the limited variation in the path of the original motion.
        
        
          
          Figure 7: The left image shows a walking motion generated to fit to a path that spells “Hello” in cursive. The right image shows a karate motion fit to the same path. The total calculation time for the walking motion was 58.1 seconds and the animation itself is 54.9 seconds. The 87.7-second karate motion was computed in just 15.0 seconds. All computation was done on a 1.3gHz Athlon.
        
        
          
          Figure 8: These images are both fits to paths wherein the character is required to walk, then sneak, and finally perform martial arts moves. The desired transition points are indicated by where the curve changes color. Note that the character both fits the path accurately and switches to the appropriate motion type close to the desired location.
        
        9
        To appear in Proceedings of SIGGRAPH ’02
      
      
        <h1>Acknowledgements</h1>
        <DRI_Unspecified agreement="All_Equal">We would like to acknowledge Andrew Gardner, Alex Mohr, and John Schreiner for assisting in video production, proofreading, and other technical matters.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">We also thank the University of Southern California’s School of Film and Television for their support and the reviewers for their many useful suggestions.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">Our work was made possible through generous motion data donations from Spectrum Studios (particularly Demian Gordon), House of Moves, and The Ohio State University.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">This work was supported in part by NSF grants CCR-9984506 and IIS-0097456, the U.S. Army 2 , the Wisconsin Alumni Research Fund’s University Industrial Relations program, equipment donations from IBM, NVidia, and Intel, and software donations from Discreet, Alias/Wavefront, and Pixar.</DRI_Unspecified>
      
      
        <h1>References</h1>
        
          A RIKAN , O., AND F ORSYTHE , D. 2002. Interactive motion generation from examples. In Proceedings of ACM SIGGRAPH 2002, Annual Conference Series, ACM SIGGRAPH.
          B OWDEN , R. 2000. Learning statistical models of human motion. In IEEE Workshop on Human Modelling, Analysis, and Synthesis, CVPR 2000, IEEE Computer Society.
          B RAND , M., AND H ERTZMANN , A. 2000. Style machines. In Proceedings of ACM SIGGRAPH 2000, Annual Conference Series, ACM SIGGRAPH, 183–192.
          B RUDERLIN , A., AND C ALVERT , T. 1996. Knowledge-driven, interactive animation of human running. In Graphics Interface, Canadian Human-Computer Communications Society, 213–221.
          B RUDERLIN , A., AND W ILLIAMS , L. 1995. Motion signal processing. In Proceedings of ACM SIGGRAPH 95, Annual Conference Series, ACM SIGGRAPH, 97–104.
          F ALOUTSOS , P., VAN DE P ANNE , M., AND T ERZOPOULOS , D. 2001. Composable controllers for physics-based character animation. In Proceedings of ACM SIGGRAPH 2001, Annual Conference Series, ACM SIGGRAPH, 251–260.
          G ALATA , A., J OGNSON , N., AND H OGG , D. 2001. Learning variable-length markov models of behavior. Computer Vision and Image Understanding Journal 81, 3, 398–413.
          G LEICHER , M. 1998. Retargeting motion to new characters. In Proceedings 0f ACM SIGGRAPH 98, Annual Conference Series, ACM SIGGRAPH, 33–42.
          G LEICHER , M. 2001. Motion path editing. In Proceedings 2001 ACM Symposium on Interactive 3D Graphics, ACM.
          H ODGINS , J. K., W OOTEN , W. L., B ROGAN , D. C., AND O’B RIEN , J. F. 1995. Animating human athletics. In Proceedings of ACM SIGGRAPH 95, Annual Conference Series, ACM SIGGRAPH, 71–78.
          K OVAR , L., G LEICHER , M., AND S CHREINER , J. 2002. Footskate cleanup for motion capture editing. Tech. rep., University of Wisconsin, Madison.
          L AMOURET , A., AND P ANNE , M. 1996. Motion synthesis by example. Computer animation and Simulation, 199–212.
          L EE , J., AND S HIN , S. Y. 1999. A hierarchical approach to interactive motion editing for human-like figures. In Proceedings of ACM SIGGRAPH 99, Annual Conference Series, ACM SIGGRAPH, 39–48.
          L EE , J., C HAI , J., R EITSMA , P. S. A., H ODGINS , J. K., AND P OLLARD , N. S. 2002. Interactive control of avatars animated with human motion data. In Proceedings of ACM SIGGRAPH 2002, Annual Conference Series, ACM SIGGRAPH.
          L EE , J. 2000. A hierarchical approach to motion analysis and synthesis for articulated figures. PhD thesis, Department of Computer Science, Korea Advanced Institute of Science and Technology.
          L I , Y., W ANG , T., AND S HUM , H.-Y. 2002. Motion texture: A two-level statistical model for character motion synthesis. In Proceedings of ACM SIGGRAPH 2002, Annual Conference Series, ACM SIGGRAPH. 2 This paper does not necessarily reflect the position or the policy of the
          Government, and no official endorsement should be inferred
          M IZUGUCHI , M., B UCHANAN , J., AND C ALVERT , T. 2001. Data driven motion transitions for interactive games. In Eurographics 2001 Short Presentations.
          M OLINA -T ANCO , L., AND H ILTON , A. 2000. Realistic synthesis of novel human movements from a database of motion capture examples. In Proceedings of the Workshop on Human Motion, IEEE Computer Society, 137–142.
          M ULTON , F., F RANCE , L., C ANI , M.-P., AND D EBUNNE , G. 1999. Computer animation of human walking: a survey. The Journal of Visualization and Computer Animation 10, 39–54. Published under the name Marie-Paule Cani-Gascuel.
          P ERLIN , K., AND G OLDBERG , A. 1996. Improv: A system for scripting interactive actors in virtual worlds. In Proceedings of ACM SIGGRAPH 96, ACM SIGGRAPH, 205–216.
          P ERLIN , K. 1995. Real time responsive animation with personality. IEEE Transactions on Visualization and Computer Graphics 1, 1 (Mar.), 5–15.
          P ULLEN , K., AND B REGLER , C. 2000. Animating by multi-level sampling. In IEEE Computer Animation Conference, CGS and IEEE, 36–42.
          P ULLEN , K., AND B REGLER , C. 2002. Motion capture assisted animation: Texturing and synthesis. In Proceedings of ACM SIGGRAPH 2002, Annual Conference Series, ACM SIGGRAPH.
          R OSE , C., G UENTER , B., B ODENHEIMER , B., AND C OHEN , M. F. 1996. Efficient generation of motion transitions using spacetime constraints. In Proceedings of ACM SIGGRAPH 1996, Annual Conference Series, ACM SIGGRAPH, 147–154.
          R OSE , C., C OHEN , M., AND B ODENHEIMER , B. 1998. Verbs and adverbs: Multidimensional motion interpolation. IEEE Computer Graphics and Application 18, 5, 32–40.
          S CH ODL  ̈ , A., S ZELISKI , R., S ALESIN , D., AND E SSA , I. 2000. Video textures. In Proceedings of ACM SIGGRAPH 2000, Annual Conference Series, ACM SIGGRAPH, 489–498.
          S UN , H. C., AND M ETAXAS , D. N. 2001. Automating gait animation. In Proceedings of ACM SIGGRAPH 2001, Annual Conference Series, ACM SIGGRAPH, 261– 270.
          W ASHBURN , D. 2001. The quest for pure motion capture. Game Developer (December).
          W ILEY , D., AND H AHN , J. 1997. Interpolation synthesis of articulated figure motion. IEEE Computer Graphics and Application 17, 6, 39–45.
          W ITKIN , A., AND P OPOVI C  ́ , Z. 1995. Motion warping. In Proceedings of ACM SIGGRAPH 95, Annual Conference Series, ACM SIGGRAPH, 105–108.
        
        10
      
    
  
</Document>