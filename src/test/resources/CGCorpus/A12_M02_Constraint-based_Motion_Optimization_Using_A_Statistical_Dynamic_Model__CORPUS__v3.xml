<?xml version="1.0" encoding="UTF-8" ?>
<Document corpusVersion="3" name="A12_M02_Constraint-based_Motion_Optimization_Using_A_Statistical_Dynamic_Model">
  
    85466c5c30862095d9d4d95af8bc76dbccf21092676aa1dbb628d1d721ff1e79
    3vt6
    http://dx.doi.org/10.1145/1276377.1276387
  
  
    
      
        <article-title>Constraint-based Motion Optimization Using A Statistical Dynamic Model</article-title>
      
      
        
          Jinxiang Chai ∗ Texas A&amp;M University
          ∗
        
      
      ∗ e-mail: jchai@cs.tamu.edu † e-mail: jkh@cs.cmu.edu
      
        
        Figure 1: Motions computed from spatial-temporal constraints.
      
      <DRI_Challenge_Goal ann2="DRI_Outcome_Contribution" agreement="2equal_1diff" ann1="DRI_Challenge_Goal" ann3="DRI_Challenge_Goal">In this paper, we present a technique for generating animation from a variety of user-defined constraints.</DRI_Challenge_Goal> <DRI_Approach agreement="All_Equal">We pose constraint-based motion synthesis as a maximum a posterior (MAP) problem and develop an optimization framework that generates natural motion satisfying user constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">The system automatically learns a statistical dynamic model from motion capture data and then enforces it as a motion prior.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Challenge">This motion prior, together with user-defined constraints, comprises a trajectory optimization problem.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Challenge_Hypothesis">Solving this problem in the low-dimensional space yields optimal natural motion that achieves the goals specified by the user.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">We demonstrate the effectiveness of this approach by generating whole-body and facial motion from a variety of spatial-temporal constraints.</DRI_Outcome> <Sentence ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="Sentence" ann3="Sentence">CR Categories: I.3.7 [Computer Graphics]: Three-Dimensional Graphics and Realism—animation; I.3.6 [Computer Graphics]: Methodology and Techniques—interaction techniques Keywords: human body animation, facial animation, motion control, statistical dynamic models, spatial-temporal constraints, constraint-based motion synthesis, motion capture data</Sentence>
      
        
          Jessica K. Hodgins † Carnegie Mellon University
          †
        
      
    
    
      
        <h1>1 Introduction</h1>
      
      <DRI_Challenge_Goal agreement="All_Equal">Our objective in this paper is to design an animation system that allows users to easily create natural-looking character animation by specifying spatial-temporal constraints throughout the motion.</DRI_Challenge_Goal> <DRI_Challenge ann2="Sentence" agreement="3diff" ann1="DRI_Challenge" ann3="DRI_Approach">For
      example, a naive user might use a performance animation system to control the trajectories of the end-positions of the limbs of a character.</DRI_Challenge> <DRI_Challenge ann2="DRI_Outcome" agreement="3diff" ann1="DRI_Challenge" ann3="DRI_Approach">A more skilled user might specify a small set of poses at key time instants.</DRI_Challenge> <DRI_Challenge ann2="DRI_Outcome" agreement="3diff" ann1="DRI_Challenge" ann3="DRI_Approach">The system then automatically finds a motion that best satisfies those constraints.</DRI_Challenge> <DRI_Challenge_Goal ann2="DRI_Challenge_Goal" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge_Goal">An ideal motion synthesis system should allow users to specify a variety of constraints either at isolated points or across the entire motion in order to accommodate users with different skill levels.</DRI_Challenge_Goal> <DRI_Background agreement="All_Equal">One appealing solution to this problem is physically based optimization [Witkin and Kass 1988], which allows the user to specify various constraints throughout the motion and relies on optimization to compute the physically valid motion that best satisfies these constraints.</DRI_Background> <DRI_Challenge agreement="All_Equal">Unfortunately, correct physics does not ensure that the motion will appear natural for characters with many degrees of freedom.</DRI_Challenge> <DRI_Approach agreement="All_Equal">Like physically based optimization, we formulate the problem as a trajectory optimization and consider the entire motion simultaneously.</DRI_Approach> <DRI_Approach agreement="All_Equal">Instead of using the physical laws to generate physically correct animation, we rely on statistical models of human motion to generate a statistically plausible motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">Our approach allows the user to generate a wide range of human body and facial animation by specifying spatial-temporal constraints throughout the motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">The system automatically learns a statistical dynamic model from motion capture data and then enforces this model as a motion prior.</DRI_Approach> <DRI_Approach agreement="All_Equal">The statistical dynamic model plays a role similar to that played by the dynamics in physically based optimization because it constrains the motion to only part of the space of possible human motions.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">The statistical dynamic model, however, is usually lower dimensional than the dynamics model, making the optimization more efficient, less likely to be subject to local minima, and more likely to produce natural motion.</DRI_Approach> <DRI_Outcome agreement="All_Equal">We demonstrate the effectiveness of this approach in two domains: human body animation and facial animation.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">We show that the system can generate natural-looking animation from key-frame constraints, key-trajectory constraints, and a combination of these two constraints.</DRI_Outcome> <DRI_Approach agreement="All_Equal">For example, the user can generate a walking animation from a small set of key frames and foot contact constraints ( figure 1 top).</DRI_Approach> <DRI_Approach agreement="All_Equal">The user can also specify a small set of key trajectories for the root, hands and feet positions to generate a realistic jumping motion ( figure 1 bottom).</DRI_Approach> <DRI_Approach agreement="All_Equal">The user can fine tune the animation by incrementally modifying the constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">The system can generate motions for a character whose skeletal model is markedly different from those of the subjects in the database.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">We also show that the system can use a statistical dynamic model learned from a normal walking sequence to create new motion such as walking on a slope.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">The quality of the final animation produced by our system depends on the motion priors derived from the motion capture database and the number of user-defined constraints.</DRI_Outcome> <DRI_Approach agreement="All_Equal">We, therefore, evaluate how the database influences the final motion and how increasing or decreasing the number of user-defined constraints influences the final animation.</DRI_Approach> <DRI_Approach agreement="All_Equal">We also compare alternative techniques for generating animation from user-defined constraints such as linear interpolation, trajectory-based inverse kinematics, and inverse kinematics in a PCA subspace.</DRI_Approach>
      
        <h1>2 Background</h1>
        <DRI_Challenge_Goal ann2="DRI_Outcome_Contribution" agreement="3diff" ann1="DRI_Challenge_Goal" ann3="DRI_Approach">In this paper, we construct statistical models from motion capture data and then combine these models with trajectory optimization to generate a motion that satisfies user-defined constraints.</DRI_Challenge_Goal> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Approach">Consequently, we discuss related work in constraint-based trajectory optimization and data-driven animation with an emphasis on statistical models.</DRI_Background>
        
          <h2>2.1 Constraint-based Trajectory Optimization</h2>
          <DRI_Background agreement="All_Equal">Trajectory optimization methods, which were first introduced to the graphics community by Witkin and Kass [1988], provide a powerful framework for generating character animation from user-specified constraints, physics constraints, and an objective function that measures the performance of a generated motion.</DRI_Background> <DRI_Challenge ann2="DRI_Challenge" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">Extending this approach to generate natural motion for a full human character has proved to be hard because the system is high dimensional, the physics constraints make it highly nonlinear, and defining an objective function that reliably measures the naturalness of human motion is difficult.</DRI_Challenge> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">Much of the difficulty in solving this problem appears to result from the physics constraints because optimization without physics is effective for editing [Gleicher 1998].</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">Therefore, one way to make the problem tractable is to simplify the governing physical laws.</DRI_Background> <DRI_Background agreement="All_Equal">Both Liu and Popović [2002] and Abe and his colleagues [2004] showed that many dynamic effects can be preserved by enforcing patterns of linear and angular momentum during the motion.</DRI_Background> <DRI_Background agreement="All_Equal">Reformulating the dynamics to avoid directly computing the torques also provides a significant performance improvement [Fang and Pollard 2003].</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">Reducing the number of degrees of freedom to be optimized can also create tractable problems.</DRI_Background> <DRI_Background agreement="All_Equal">For example, Popović and Witkin [1999] showed that significant changes to motion capture data can be made by manually reducing the degrees of freedom to those most important for the task.</DRI_Background> <DRI_Background agreement="All_Equal">Safonova and her colleagues [2004] demonstrated that an efficient optimization can be achieved in a behavior-specific, low-dimensional space without simplifying the dynamics.</DRI_Background> <DRI_Background agreement="All_Equal">More recently, Liu and her colleagues [2005] introduced a novel optimization framework— Nonlinear Inverse Optimization—for optimizing appropriate parameters of the objective function from a small set of motion examples and then used the estimated parameters to synthesize a new locomotion.</DRI_Background> <DRI_Approach agreement="All_Equal">Our work also uses a trajectory optimization framework but replaces the physical dynamic model with a statistical dynamic model computed from a motion capture database.</DRI_Approach>
        
        
          <h2>2.2 Data-driven Motion Synthesis</h2>
          <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Our approach is also part of an alternative set of techniques that relies on motion data to constrain the search to natural looking motions.</DRI_Approach> <DRI_Background agreement="All_Equal">For example, motion graphs can be used to resequence whole-body or facial motions (see, for example, [Arikan and Forsyth 2002; Kovar et al. 2002; Lee et al. 2002; Zhang et al. 2004].</DRI_Background> <DRI_Background agreement="All_Equal">These systems cannot match poses or satisfy such kinematic constraints as end effector constraints unless the motion database happens to contain a motion that satisfies those constraints.</DRI_Background> <DRI_Background agreement="All_Equal">Motion interpolation, on the other hand, does allow isolated constraints to be satisfied (for example, [Rose et al. 1998; Kovar and Gleicher 2004; Mukai and Kuriyama 2005]).</DRI_Background> <DRI_Background agreement="All_Equal">However, interpolation across a complete behavior does not have enough degrees of freedom to allow the specification of full pose constraints or end effector constraints across multiple frames.</DRI_Background> <DRI_Background agreement="All_Equal">Recently, interpolation and motion graphs have been combined to obtain some of the advantages of each approach [Safonova and Hodgins 2007].</DRI_Background> <DRI_Background agreement="All_Equal">Statistical models of human motion have also been used for motion synthesis.</DRI_Background> <DRI_Background agreement="All_Equal">A number of researchers have used variants of Hidden Markov Models (HMMs) to statistically represent human motion: either full-body movements [Molina Tanco and Hilton 2000; Brand and Hertzmann 2000; Galata et al. 2001] or speechdriven facial expressions [Bregler et al. 1997; Brand 1999].</DRI_Background> <DRI_Background agreement="All_Equal">HMMs learned from human motion data have been used to interpolate key frames [Molina Tanco and Hilton 2000; Galata et al. 2001], synthesize a new style of motion [Brand and Hertzmann 2000], and generate facial expressions from speech signals [Bregler et al. 1997; Brand 1999].</DRI_Background> <DRI_Background agreement="All_Equal">Grzeszczuk and his colleagues[1998] developed a neural network approximation of dynamics based on simulated data and use it to animate dynamic models such as fish and lunar landers.</DRI_Background> <DRI_Background agreement="All_Equal">Urtasun and her colleagues[2006] learned linear motion models from pre-aligned motion data via Principal Component Analysis (PCA) and used them to track 3D human body movements from video by performing nonlinear optimization over a small sliding temporal window.</DRI_Background> <DRI_Background agreement="All_Equal">Switching linear dynamic system (SLDS) have also been used to model human motion.</DRI_Background> <DRI_Background agreement="All_Equal">Pavlović and his colleagues [2000] present results for human motion synthesis, classification, and visual tracking using learned SLDS models.</DRI_Background> <DRI_Background agreement="All_Equal">Li and his colleagues [2002] used SLDS to synthesize and edit disco dancing motion.</DRI_Background> <DRI_Approach agreement="All_Equal">Our approach is also to learn a statistical dynamic model from human motion capture data; however, the dynamic behavior of our model is controlled by a continuous control state rather than a discrete hidden state as in HMMs and SLDS.</DRI_Approach> <DRI_Approach agreement="All_Equal">This property led us to formulate the motion synthesis problem as a trajectory optimization problem.</DRI_Approach> <DRI_Approach agreement="All_Equal">More importantly, our system allows the user to specify a variety of spatial-temporal constraints such as end effector constraints throughout the motion, a capability that has not been demonstrated by previous approaches.</DRI_Approach> <DRI_Background agreement="All_Equal">A number of researchers have developed statistical models for human poses and used them to solve the inverse kinematics problem.</DRI_Background> <DRI_Background agreement="All_Equal">Grochow and colleagues [2004] applied a global nonlinear dimensionality reduction technique, Gaussian Process Latent Variable Model, to human motion data and then used the learned statistical pose model to compute poses from a small set of user-defined constraints.</DRI_Background> <DRI_Background agreement="All_Equal">Another solution for data-driven inverse kinematics is to interpolate a small set of preexisting examples using constraints.</DRI_Background> <DRI_Background agreement="All_Equal">This idea has been used to compute human body poses [Rose et al. 2001] and facial expressions [Zhang et al. 2004] from kinematic constraints at a single frame.</DRI_Background> <DRI_Background agreement="All_Equal">These models lack temporal information and therefore cannot be used to generate an animation from sparse constraints such as key frames.</DRI_Background> <DRI_Background agreement="All_Equal">Local statistical models are sufficient if the user provides continuous control signals (the performance animation problem).</DRI_Background> <DRI_Background agreement="All_Equal">Chai and colleagues [2003] presented a real-time vision-based performance animation system that transforms a small set of automatically tracked facial features into facial animation by interpolating examples in a database at run time.</DRI_Background> <DRI_Background agreement="All_Equal">They also used a series of local statistical pose models constructed at run time to reconstruct full-body motion from continuous, low-dimensional control signals obtained from video cameras [Chai and Hodgins 2005].</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">The statistical dynamic model used in this paper was motivated by the dynamic model used for video textures by Soatto and his colleagues [2001].</DRI_Approach> <DRI_Background agreement="All_Equal">They showed that a sequence of images of such moving scenes as sea-waves, smoke, and whirlwinds can be modeled by second-order linear dynamic systems.</DRI_Background> <DRI_Background agreement="All_Equal">They applied the learned dynamic systems to synthesize an “infinite length” texture sequence by sampling noise from a known Gaussian distribution.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Challenge_Goal">We extend the model to learn an efficient and low-dimensional representation of human motion and use it to generate an animation that achieves the goal specified by the user.</DRI_Approach>
        
      
      
        <h1>3 Overview</h1>
        <DRI_Challenge_Hypothesis ann2="DRI_Background" agreement="3diff" ann1="DRI_Challenge_Hypothesis" ann3="DRI_Approach">The key idea behind our approach is that motion priors learned from prerecorded motion data can be used to create natural human motion that matches constraints specified by the user.</DRI_Challenge_Hypothesis> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge_Hypothesis" ann3="DRI_Approach">The combination of the motion prior and the user’s constraints provides sufficient information to produce motion with a natural appearance.</DRI_Approach> <DRI_Approach agreement="All_Equal">The human body motion capture database (about 15 minutes) includes data of locomotion (jumping, running, walking, and hopping) and interacting with the environment (standing up/sitting down, reaching/picking up/placing an object).</DRI_Approach> <DRI_Approach agreement="All_Equal">The facial expression database (about 9 minutes) includes six basic facial expressions (happiness, surprise, disgust, fear, anger, sadness) and three facial movements related to everyday life (speaking, eating, and snoring).</DRI_Approach> <DRI_Approach agreement="All_Equal">The motion was captured with a Vicon motion capture system of 12 MX-40 cameras [Vicon Systems 2004] with 41 markers for full-body movements and 92 markers for facial expressions.</DRI_Approach> <DRI_Approach agreement="All_Equal">The motion was captured at 120Hz and then downsampled to 30Hz.</DRI_Approach> <Sentence agreement="All_Equal">We denote the set of motion capture data in the database as y 1:N = [y 1 , ...</Sentence><Sentence agreement="All_Equal">, y N ], where y n , n = 1, ...</Sentence><Sentence agreement="All_Equal">, N, is the measurement of the character’s configuration in the nth frame.</Sentence> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">In facial animation, y n is the 3D positions of all vertices on the face model.</DRI_Approach> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">In human body animation, y n is the position and orientation of the root and the joint angles.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="Sentence">We preprocess the motion capture data by applying Principal Component Analysis (PCA) [Bishop 1996] to the motion capture data and obtain a reduced subspace representation for y n :</DRI_Approach>
        
          1
          y n = C · x n + D
        
        <Sentence agreement="All_Equal">where the vector x n ∈ R d x is a low-dimensional representation of the character configuration y n ∈ R d y .</Sentence> <DRI_Approach agreement="All_Equal">The matrix C is constructed from the eigenvectors corresponding to the largest eigenvalues of the covariance matrix of the data, and D is the mean of all example data, D = (Σ N n=1 y n )/N .</DRI_Approach> <DRI_Approach agreement="All_Equal">The dimensionality of the system state, d x , can be automatically determined by choosing the d x for which the singular values drop below a threshold.</DRI_Approach> <Sentence agreement="All_Equal">The constraints defined by the user are represented by E = {e j |j = 1, ...</Sentence><Sentence agreement="All_Equal">, J}.</Sentence> <Sentence agreement="All_Equal">The goal of our constraint-based motion synthesis problem is to create an animation, H, based on the constraints, E. We formulate the constraint-based motion synthesis in a maximum a posterior (MAP) framework and consider the entire motion simultaneously.</Sentence> <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Approach" ann3="Sentence">From Bayes’ theorem, the goal of MAP is to infer the
        most likely motion, H, given the user-defined constraints, E:</Sentence>
        
          2
          p (E|H) p (H) arg max H p(H|E) = arg max H p (E) ∝ arg max H p(E|H)p(H)
        
        <Sentence agreement="All_Equal">where p(E)is the normalizing constant that ensures that the posterior distribution on the left-hand side is a valid probability density and integrates to one.</Sentence> <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Approach" ann3="Sentence">In our implementation, we minimize the negative log of p(H|E), yielding the following optimization for motion H: ˆ</Sentence>
        
          3
          H ˆ = arg min H − ln p(E|H) − ln p(H)
        
        <Sentence agreement="All_Equal">where the first term measures how well a motion sequence matches the user-specified constraints and the second term measures a priori likelihood of the motion sequence using the knowledge embedded in human motion data.</Sentence> <Sentence agreement="All_Equal">The system contains three major components: Motion prior.</Sentence> <DRI_Approach agreement="All_Equal">The system first automatically learns a statistical dynamic model from motion capture data.</DRI_Approach> <DRI_Approach agreement="All_Equal">This model is then used to compute the motion prior, − ln p(H).</DRI_Approach> <Sentence ann2="DRI_Approach" agreement="3diff" ann1="Sentence" ann3="DRI_Unspecified">User-defined Constraints.</Sentence> <DRI_Approach agreement="All_Equal">The user defines various forms of constraints, E, throughout the motion, which are then used to compute the likelihood term, − ln p(E|H).</DRI_Approach> <DRI_Approach agreement="All_Equal">The constraints could be any kinematic constraints such as position, orientation, or the distance between two points on the character.</DRI_Approach> <DRI_Approach agreement="All_Equal">They could be specified either at isolated points (key frames) or across the whole motion (key trajectories).</DRI_Approach> <Sentence ann2="DRI_Approach" agreement="3diff" ann1="Sentence" ann3="DRI_Unspecified">Motion optimization.</Sentence> <DRI_Approach agreement="All_Equal">The system uses trajectory optimization to automatically find an animation H ˆ that best satisfies the userspecified constraints while matching the statistical properties of the motion capture data: H ˆ = arg min H − ln p(E|H) − ln p(H).</DRI_Approach> <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">We describe the statistical model in the next section and then present the three components in detail in section 5.</DRI_Unspecified>
      
      
        <h1>4 Motion Analysis</h1>
        <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Approach" ann3="Sentence">We use an m-order linear time-invariant system to describe the dynamical behavior of the captured motion in the low-dimensional space [Ljung 1999]: m</Sentence>
        
          4
          x n = A i x n−i + Bu n i=1
        
        <Sentence agreement="All_Equal">where m is the order of the linear dynamic model.</Sentence> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Approach">x n ∈ R d x and u n ∈ R d u are the system state and control input, and d u is the dimensionality of the control input u n .</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Approach">This formulation is similar to the linear time-invariant control system commonly adopted in the control community [Palm 1999].</DRI_Approach> <DRI_Approach agreement="All_Equal">However, the matrix B is not unique because the control input u t is unknown.</DRI_Approach> <DRI_Approach agreement="All_Equal">Therefore, any non-singular transformation of the matrix B represents the motion because BT and T −1 u n are also consistent with the dynamic model.</DRI_Approach> <DRI_Approach agreement="All_Equal">To remove this ambiguity, we assume that the matrix B is an orthogonal matrix.</DRI_Approach> <Sentence agreement="All_Equal">Given the low-dimensional representation of the original motion capture data, x 1:N = [x 1 , ...</Sentence><Sentence agreement="All_Equal">, x N ], we want to identify the statespace model, including system matrices {A i |i = 1, ...</Sentence><Sentence agreement="All_Equal">, m}, B, and the corresponding control input u m+1:N = [u m+1 , ...</Sentence><Sentence agreement="All_Equal">, u N ].</Sentence> <Sentence agreement="All_Equal">The matrices {A i |i = 1, ...</Sentence><Sentence agreement="All_Equal">, m} are dependent on the distribution of u n .</Sentence> <Sentence agreement="All_Equal">To eliminate the ambiguity of the matrices A i , we seek to</Sentence>
        
          
          
        
        <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Unspecified">(a)</Sentence>
        
          Figure 2: The average reconstruction error of the linear time-invariant system computed by cross-validation techniques: (a) The average per frame reconstruction error for the walking test data as a function of the order of the dynamic system (m) and the number of dimensions of the control input (d u ); (b) The average per frame reconstruction error of the facial test data as a function of the order of the dynamic system (m) and the number of dimensions of the control input (d u ).
        
        find the {A i |i = 1, ..., m} that minimize the sum of the squared control input u n :
        
          5
          A ˆ 1 , ..., A ˆ m = arg min A 1 ,...,A m n u n 2
        
        <Sentence agreement="All_Equal">The matrices A i can thus be uniquely found by computing the leastsquare solution:
        A ˆ 1 , ...</Sentence><Sentence agreement="All_Equal">, A ˆ m = arg min A 1 ,...</Sentence><Sentence agreement="All_Equal">,Am n=m+1 N x n − i=1 m A i x n−i 2 (6) We use the estimated matrices {A i |i = 1, ...</Sentence><Sentence agreement="All_Equal">, m} to compute the control input term:</Sentence>
        
          7
          z n = x n − i=1 m A ˆ i x n−i , n = m + 1, ..., N
        
        <Sentence agreement="All_Equal">We form a d x × (N − m) matrix by stacking the estimated control inputs z n : z m+1 ...</Sentence> <Sentence agreement="All_Equal">z N = B· u m+1 ...</Sentence> <Sentence agreement="All_Equal">u N (8) Z U
        Equation (8) shows that without noise, the rank of the matrix Z is d u .</Sentence> <Sentence ann2="DRI_Approach" agreement="2equal_1diff" ann1="Sentence" ann3="Sentence">Therefore, we can automatically determine the dimensionality of the control input u n by computing the rank of matrix Z. When noise corrupts the motion capture data, the data matrix Z will not be exactly of rank d u .</Sentence> <DRI_Approach agreement="All_Equal">However, we can perform singular value decomposition (SVD) on the data matrix Z such that Z = W SV T , and then get the best possible rank d u approximation of the data matrix, factoring it into two matrices: B ˆ = W and U ˆ = SV T , where B ˆ is a d x × d u matrix and U ˆ is a d u × (T − m) matrix.</DRI_Approach> <DRI_Approach agreement="All_Equal">The dimensionality of the control input (d u ) can be automatically determined by choosing the d u for which the singular values drop below a threshold.</DRI_Approach> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">Functionally, a statistical dynamic model is similar to a physical dynamic model.</DRI_Approach> <Sentence agreement="All_Equal">For example, given initial values of the system state</Sentence>
        
          4
          (x 1:m = [x 1 , ..., x m ]), the linear dynamic model in Equation
        
        <Sentence agreement="All_Equal">can be used to generate an animation (x m+1:T = [x m+1 , ...</Sentence><Sentence agreement="All_Equal">, x T ]) by sequentially choosing an appropriate value for the control input (u m+1:T = [u m+1 , ...</Sentence><Sentence agreement="All_Equal">, u T ]), just as joint torques would be used to advance a physical model through time.</Sentence> <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Approach">The main advantage
        (b)
        of using a statistical dynamic model for animation is that the dimensionality of the control input in a statistical dynamic model is usually much lower than a physical dynamic model.</Sentence> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">Therefore, the statistical dynamic model might achieve faster convergence and be less subject to local minima.</DRI_Approach> <DRI_Approach agreement="All_Equal">The number of dimensions of the control input, d u , characterizes the complexity of our dynamic model.</DRI_Approach> <DRI_Unspecified ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Unspecified">Figure 2 plots the reconstruction error of a walking test data set and a facial test data set as a function of the order of the dynamic system (m) and the number of dimensions of the control input, d u .</DRI_Unspecified> <DRI_Approach agreement="All_Equal">The walk data set is from multiple subjects and contains different styles.</DRI_Approach> <DRI_Approach agreement="All_Equal">The facial expression data are from the same subject and contain a variety of facial expressions such as “happy” and “sad.</DRI_Approach><DRI_Approach agreement="All_Equal">” The average reconstruction error is the L 2 distance between the original test motion and the motion reconstructed from the linear time-invariant system and computed by cross-validation techniques.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">We observe that the reconstruction error of the statistical model decreases as both the order of dynamic system and the number of dimensions of the control input increases.</DRI_Approach> <DRI_Approach agreement="All_Equal">If we choose d u as “zero” (simply dropping off the control term), our model becomes the linear dynamic model used by Soatto and colleagues [2001] and has the largest reconstruction error.</DRI_Approach> <DRI_Approach agreement="All_Equal">If d u is equal to the number of dimensions of the system state d x , the model can be used to represent an arbitrary motion sequence with zero error.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">In practice, human motion is highly coordinated, and the dimensionality of the control input for accurate motion representation, d u , is often much lower than the dimensionality of the system state, d x .</DRI_Approach> <DRI_Approach agreement="All_Equal">For the examples reported here, we set the dynamic order to three and the dimensionality of control input to four for human body animation (the reconstruction error is about 0.7 degrees/joint per frame); we set the dynamic order to two and the dimensionality of control input to one for facial movement (the reconstruction error is about 0.1 mm/vertex per frame).</DRI_Approach>
      
      
        <h1>5 Constraint-based Motion Synthesis</h1>
        <Sentence agreement="All_Equal">Constraint-based motion synthesis provides the user with intuitive control over the resulting motion: the user specifies a desired motion with various forms of constraints, such as key frames, end effector target positions, or joint angle values; the system then auto-</Sentence>
        
          
        
        <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Unspecified">(a)
        (b)</Sentence>
        
          Figure 3: Various form of spatial-temporal constraints: (a) key-frame constraints for creating full-body animation; (b) key-trajectory constraints where the user selects six points on the character and then specifies their 3D trajectories across the motion (from a performance animation interface); (c) the user picks six points on the face and their screen-space position constraints at some moment in time; (d) the user defines a distance between two facial points (the width of the mouth) and controls the distance throughout the motion.
        
        <Sentence agreement="All_Equal">matically finds the animation that best satisfies the user-specified constraints while matching the spatial-temporal properties of the motion capture data.</Sentence> <Sentence agreement="All_Equal">This section first derives the likelihood term, − ln p(E|H), based on the user-defined constraints, E. We then model the motion prior term, − ln p(H), using the learned statistical dynamic model.</Sentence> <DRI_Approach agreement="All_Equal">Finally, we discuss how to optimize motion by combining both terms: H ˆ = arg min H − ln p(E|H) − ln p(H).</DRI_Approach> <DRI_Approach agreement="All_Equal">Like physically based optimization [Witkin and Kass 1988], we represent the system state x t and the control signal u t independently.</DRI_Approach> <Sentence agreement="All_Equal">The motion to be synthesized is therefore represented as a sequence of system states and control inputs H = (x 1 , ...</Sentence><Sentence agreement="All_Equal">, x T , ...</Sentence><Sentence agreement="All_Equal">, u m+1 , ...</Sentence><Sentence agreement="All_Equal">, u T ).</Sentence> <Sentence agreement="All_Equal">The system allows the user to specify various forms of kinematic constraints E = {e j |j = 1, ...</Sentence><Sentence agreement="All_Equal">, J} throughout the motion or at isolated points in the motion.</Sentence> <DRI_Approach agreement="All_Equal">For facial animation, the user can specify the positions or orientations of any points on the face, or the distance between any two points.</DRI_Approach> <DRI_Approach agreement="All_Equal">For whole-body animation, the user can specify the positions or orientations of any points on the body, or joint angle values for any joints.</DRI_Approach> <DRI_Approach agreement="All_Equal">Rather than requiring that constraints be specified in 3D, it is often more intuitive to specify where the projection of a point on the character should be located.</DRI_Approach> <DRI_Approach agreement="All_Equal">Therefore, the system also allows the user to specify the 2D projections of any 3D point on a user-defined screen space.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">This approach could be used for rotoscoping a video, or for a single camera performance animation.</DRI_Approach> <DRI_Approach agreement="All_Equal">The system allows the user to sketch out the motion in greater or lesser detail.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, a novice user might want to control the paths of specific joints or paths over a period of time using a performance animation system while a more skilled user might prefer using key frame constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">Spatially, the constraints could provide either an exact configuration such as a full-body pose or a small subset of the joint angles or end-positions.</DRI_Approach> <DRI_Approach agreement="All_Equal">Temporally, the constraints could be instantaneous constraints for a particular frame, multiple-frame constraints, or continuous constraints over a period of time.</DRI_Approach> <DRI_Approach agreement="All_Equal">User-defined constraints can be linear or nonlinear.</DRI_Approach> <DRI_Approach agreement="All_Equal">Linear constraints can be used to define joint angle constraints in human body animation and positions in facial animation.</DRI_Approach> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">The most common nonlinear constraints in human body animation might be end effector constraints, for example, foot contact constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">In facial animation, nonlinear constraints can be used to specify the distance between two points on the face or 2D projections of 3D facial points.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Figure 3 illustrates the user-defined constraints that were used to generate human body animation and facial animation.</DRI_Unspecified>
        5.1 User-defined Constraints
        <Sentence agreement="All_Equal">Mathematically, we can model the likelihood term, − ln p(E|H), as
        (c)
        (d)
        follows:
        E constraints = − ln p(E|H) ∼ j=1 J β e j − f j (y 1 , ...</Sentence><Sentence agreement="All_Equal">, y T ) 2 ∼ j=1 J β e j − f j (Cx 1 + D, ...</Sentence><Sentence agreement="All_Equal">, Cx T + D) 2 (9) where the function f j is usually a forward kinematics function and the parameter β is a constant specifying the importance of the constraints.</Sentence> <DRI_Approach agreement="All_Equal">The likelihood term evaluates how well the synthesized motion matches the constraints specified by the user.</DRI_Approach> <DRI_Approach agreement="All_Equal">A good match between the motion and the user-defined constraints results in a low energy solution.</DRI_Approach>
        
          <h2>5.2 Motion Priors</h2>
          <DRI_Approach agreement="All_Equal">Many motions might satisfy the user-defined constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, when the user specifies a small set of key frames or key trajectories, the number of constraints is not sufficient to completely determine the whole motion sequence, x 1:T .</DRI_Approach> <DRI_Approach agreement="All_Equal">To remove ambiguities, we would like to constrain the generated motion to lie in the space of natural human motions by imposing a prior on the generated motion:</DRI_Approach>
          
            10
            E prior = − ln p(H)
          
          
            10
            = − ln p(x 1:T , u m+1:T )
          
          <DRI_Approach agreement="All_Equal">Based on the statistical dynamic equation (Equation 4), the current system state x t only depends on the previous system states x t−m:t−1 and the current control input u t .</DRI_Approach> <Sentence ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Background" ann3="Sentence">We have p(H) = p(x 1:T , u m+1:T ) T = t=m+1 p(x t |x t−1:t−m , u t ) · p(x 1:m , u m+1:T ) (11) We assume that the likelihood of the first term on the right side of Equation 11 is measured by the deviation of the statistical dynamic equation (Equation 4).</Sentence> <DRI_Approach agreement="All_Equal">We have the corresponding energy term E prior dynamic = − ln T t=m+1 p(x t |x t−1:t−m , u t ) ∼ −α T t=m+1 x t − i=1 m A i x t−i − Bu t 2 (12) where α is a tuning parameter.</DRI_Approach> <DRI_Approach agreement="All_Equal">Conceptually, the dynamic prior can be thought as dimensionality reduction of the motion in a spatialtemporal domain.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">It significantly reduces the dimensionality of the motion from the space of x 1:T to the space of the initial state x 1:m and the control input u m+1:T .</DRI_Approach> <DRI_Approach agreement="All_Equal">The second term on the right side of Equation 11 computes the prior for the initial state, x 1:m , and control input, u m+1:T .</DRI_Approach> <DRI_Approach agreement="All_Equal">We assume that both the initial state, x 1:m , and the control input, u t , are independent and identically distributed.</DRI_Approach> <DRI_Approach ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">The energy term for the second term on the right side of Equation 11 can be simplified as follows:</DRI_Approach>
          
            
            Figure 4: The horizontal axis shows the iteration number and the vertical axis shows the value of the objective function for wholebody optimization The three colored curves show the evolution of the objective function values with three different initial guesses. The optimization converges within 100 iterations.
          
          
            13
            E prior control = − ln p(x 1:m , u m+1:T ) m T = − t=1 ln p(x t ) − t=m+1 ln p(u t )
          
          <DRI_Approach agreement="All_Equal">We model the control input (u t ) as a mixture with K component Gaussian densities [Bishop 1996]:</DRI_Approach>
          
            14
            K p(u t ) = Σ k=1 π k N(u t ; φ k , Λ k )
          
          <Sentence agreement="All_Equal">where K is the number of Gaussian density models and π k is a mixing parameter that corresponds to the prior probability that u t was generated by the kth component.</Sentence> <DRI_Approach agreement="All_Equal">The function N(u t ; φ j , Λ j ) denotes the multivariate normal density function with mean φ j and covariance matrix Λ j .</DRI_Approach> <DRI_Approach agreement="All_Equal">The parameters of the Gaussian mixture models (π k , φ k , Λ k ) are automatically estimated using an Expectation-Maximization (EM) algorithm [Bishop 1996].</DRI_Approach> <Sentence ann2="DRI_Approach" agreement="2equal_1diff" ann1="Sentence" ann3="Sentence">The training data are the values of control inputs { u n } computed from the original motion capture data ({y n |n = 1, ...</Sentence><Sentence agreement="All_Equal">, N }) (see section 4).</Sentence> <Sentence agreement="All_Equal">The density function of the initial states, p(x t ), t = 1, ...</Sentence><Sentence agreement="All_Equal">, m, is also modeled as a mixture of multivariate Gaussian distributions whose parameters are learned from motion data, x 1:N , using the EM algorithm.</Sentence> <DRI_Approach agreement="All_Equal">Note that we choose weak priors (static models) to model the priors for both initial states and control inputs so as not to restrict the type of motions the algorithm can generate.</DRI_Approach>
        
        
          <h2>5.3 Motion Optimization</h2>
          <DRI_Approach agreement="All_Equal">After combining the user-defined constraints and the motion prior, the constraint-based motion synthesis problem becomes the following unconstrained motion optimization problem:</DRI_Approach>
          
            15
            arg min x , u E constraint + E prior dynamic + E prior control
          
          <Sentence agreement="All_Equal">where x and u are the concatenation of the system states x t and the concatenation of the control signals u t over the entire motion.</Sentence> <DRI_Approach agreement="All_Equal">We follow a standard approach of representing x t and u t using cubic B-splines.</DRI_Approach> <DRI_Approach agreement="All_Equal">We solve the optimization problem using sequential quadratic programming (SQP) [Bazaraa et al. 1993], where each iteration solves a quadratic programming subproblem.</DRI_Approach> <DRI_Approach agreement="All_Equal">The Jacobian matrix and the Hessian matrix of the energy function are symbolically evaluated at each iteration.</DRI_Approach> <DRI_Approach agreement="All_Equal">We choose all initial values using random values between 0 and 1 except that a linear interpolation of the user-specified keyframe constraints is used for initialization.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">We found that the optimization procedure always converges quickly (usually less than 100 iterations and less than 30 seconds).</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Typically, the objective function values decrease rapidly in the early iterations and then level off as they approach the optimal value.</DRI_Approach> <DRI_Unspecified ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">Figure 4 shows the objective function values for three different initial guesses.</DRI_Unspecified> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">Our optimization framework can also be applied to the problem of generating human body motions for a character whose skeletal model is markedly different from the subjects in the database.</DRI_Approach> <DRI_Approach agreement="All_Equal">User-defined constraints for motion retargeting can either be directly computed from the source motion or specified by the user.</DRI_Approach> <DRI_Approach agreement="All_Equal">In our experiment, we extract foot positions from a source walking motion and then use it to generate a walking sequence for a new character.</DRI_Approach> <DRI_Approach agreement="All_Equal">We also add one term in the objective function that measures the difference between the source motion and retargeted motion:</DRI_Approach>
          
            16
            E dif f = t=1 T y t source − Cx t − D 2
          
          <Sentence agreement="All_Equal">where y t source is the source pose at frame t.</Sentence>
        
      
      
        <h1>6 Results</h1>
        <DRI_Approach agreement="All_Equal">We test our system by generating both human body animation and facial animation from various forms of user-defined constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">We also evaluate the performance of our algorithm in terms of the motion priors and user-defined constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">We learn the statistical model for each individual behavior and use it to generate individual behavior based on user-defined constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">Two kinds of constraints were used to generate most of the examples in this paper: key-frame constraints and key-trajectory constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">We can also combine these two constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">For example, a jumping motion can be created by specifying a start pose and the positions of both feet and root throughout the motion.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Unspecified">The accompanying video demonstrates the effectiveness of our system for generating a number of individual behaviors, including walking, running, and jumping.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Our behavior-specific statistical motion model is capable of generating a rich variety of actions.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">For example, we can use a small set of key frames and foot contacts to generate normal walking, climbing over an obstacle, a baby walking, and mickey-mouse style walking.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">Figure 5 shows sample frames of the results.</DRI_Unspecified> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Our system can also synthesize motion that transitions from one behavior to another by using the statistical model learned from transition data.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">In the accompanying video, we demonstrate that the user can generate a transition from walking to jumping, from walking to sitting down, and from walking to picking up an object (figure 6).</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Unspecified">The accompanying video also shows that the system can generate motions for characters with skeletal dimensions different from those in the database.</DRI_Outcome> <DRI_Unspecified agreement="All_Equal">Figure 7 shows sample frames of the results.</DRI_Unspecified> <DRI_Outcome agreement="All_Equal">We also show that we can use motion priors learned from a small sequence of a normal walking motion (about 100 frames) to create walking on a slope and walking with small steps.</DRI_Outcome> <DRI_Approach ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">The user can refine the animation by incrementally modifying the constraints.</DRI_Approach> <DRI_Approach ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">For example, the user can create a slightly different jumping motion by adjusting the positions of both hands at the top of the jump.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Figure 8 shows sample frames of the results.</DRI_Unspecified>
        6.1 Full-body Animation
        
          
          Figure 5: Animation generated by a small set of key frames: (top) baby walking; (middle) running; (bottom) stylized walking.
        
        
          
          Figure 6: Our system can generate a transition from walking to jumping using a small set of key frames.
        
        
          
          Figure 7: Motion generality: (top) The system generates motion for a character whose skeletal dimensions are different from the subjects in the database; (bottom) The system modifies a normal walking motion to create a new motion–walking on a slope.
        
        
          
          Figure 8: The user can fine tune an animation by incrementally adding constraints: (top) jumping generated by the user using five key trajectories (both hands, both feet, and root); (bottom) a slightly different jumping motion generated after adjusting the positions of the hands at the top of the jump.
        
        
          <h2>6.2 Facial Animation</h2>
          <DRI_Approach agreement="All_Equal">The system learns a single statistical model from the whole facial motion capture database and then uses it to create facial animation with a variety of spatial-temporal constraints.</DRI_Approach> <Sentence agreement="All_Equal">The following examples are illustrated in the accompanying video: Combination of keyframe and trajectory constraints.</Sentence> <DRI_Approach agreement="All_Equal">The user can generate realistic facial animation by combining sparse keyframe constraints (three key frames) and sparse trajectory constraints (one trajectory).</DRI_Approach> <DRI_Unspecified ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Unspecified">Sparse screen constraints.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">The user selects six points on the face and specifies the 2D projections on the screen space at three key instants.</DRI_Approach> <DRI_Approach agreement="All_Equal">This type of constraint could be extracted by rotoscoping.</DRI_Approach> <DRI_Unspecified ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Unspecified">Trajectory constraints.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">The user can achieve detailed control over facial movement by specifying the trajectories of a small set of 3D facial points.</DRI_Approach> <DRI_Approach agreement="All_Equal">The user can also use trajectories of a small set of high-level facial features (the mouth width and height and the openness of the eyes) to generate facial animation.</DRI_Approach>
        
        
          <h2>6.3 Evaluation</h2>
          <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">The quality of the final animation depends on the motion priors and the user-defined constraints.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="Sentence">We, therefore, have designed a number of experiments to evaluate the performance of our algorithm: The importance of the motion priors.</DRI_Approach> <DRI_Approach agreement="All_Equal">We evaluate the importance of motion priors by comparing our method against alternative constraint-based motion synthesis methods.</DRI_Approach> <DRI_Approach agreement="All_Equal">The first method is a simple linear interpolation of key frames.</DRI_Approach> <DRI_Approach agreement="All_Equal">The second method is trajectory-based inverse kinematics that minimizes the velocity changes of the motion in the original configuration space, y t , without any priors.</DRI_Approach> <DRI_Approach agreement="All_Equal">The third method is a simple data-driven inverse kinematics algorithm that minimizes the velocity changes of the motion in a reduced PCA space, x t .</DRI_Approach> <DRI_Approach agreement="All_Equal">We compare the methods using key-frame constraints and key-trajectory constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">We keep the constraints constant and use a cubic spline to represent the motion.</DRI_Approach> <DRI_Unspecified ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Unspecified">The results of this comparison are shown in the video.</DRI_Unspecified> <DRI_Outcome agreement="All_Equal">Without the use of the statistical dynamic model, the system can not generate natural motions unless the user specifies a very detailed set of constraints across the entire motion.</DRI_Outcome> <Sentence ann2="DRI_Unspecified" agreement="3diff" ann1="Sentence" ann3="DRI_Outcome">Motion priors from different databases.</Sentence> <DRI_Approach agreement="All_Equal">We evaluate how the database influences the final motion by keeping the user-defined constraints constant.</DRI_Approach> <DRI_Approach agreement="All_Equal">We have experimented with both key-frame and key-trajectory constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">For key-frame constraints, the user defined a sparse set of walking constraints and used them to generate walking motion from the priors learned from a number of different databases.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">We compare the results for a database of general locomotion, running, hopping, jumping and walking.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Unspecified">The accompanying video shows that we can generate a good walking motion with a walking database.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">The quality of the animation becomes worse when we use a large and general locomotion database to generate walking.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">As would be expected, the system fails to generate a good walking motion if the motion prior is learned from running, hopping, or jumping data.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">We have tested the creation of jumping motion from key-trajectory jumping constraints when the prior is learned from a database of jumping, general locomotion, or walking.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Similarly, the prior from a walking database fails to generate a good jumping motion because of the mismatch between the prior and the user-defined constraints.</DRI_Outcome> <DRI_Unspecified ann2="DRI_Unspecified" agreement="2equal_1diff" ann1="Sentence" ann3="DRI_Unspecified">Different numbers of constraints.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">With an appropriate database, we compare the quality of motions generated by different numbers of constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">More specifically, we take one motion sequence out of the database and use it as a testing sequence.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">We then compare the animations created by key frames that are spaced increasingly far apart in time.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">We also compare the results by decreasing the number of key trajectories.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Unspecified">The accompanying video shows that results become worse when we decrease the number of the userdefined constraints.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">For example, the numerical error increases steadily (0.94, 1.06, 1.81 degrees per joint per frame) when the number of constraints is decreased (6, 4, 2 key frames).</DRI_Outcome> <DRI_Outcome agreement="All_Equal">We observe a noticeable foot sliding artifact on one foot when two key trajectories (root and one foot) are used to create a walking motion.</DRI_Outcome>
        
      
      
        <h1>7 Discussion</h1>
        <DRI_Outcome_Contribution ann2="DRI_Outcome_Contribution" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome">We have presented an approach for generating both full-body movement and facial expression from spatial-temporal constraints while matching the statistical properties of a database of captured motion.</DRI_Outcome_Contribution> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">The system automatically learns a low-dimensional linear dynamic model from motion capture data and then enforces this as spatial-temporal priors to generate the motion.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Challenge">The statistical dynamic equations, together with an automatically derived objective function and user-defined constraints, comprise a trajectory optimization problem.</DRI_Approach> <DRI_Approach ann2="DRI_Outcome" agreement="3diff" ann1="DRI_Approach" ann3="DRI_Challenge">Solving this optimization problem in the lowdimensional space yields optimal, natural motion that achieves the goals specified by the user.</DRI_Approach> <DRI_Outcome agreement="All_Equal">The system achieves a degree of generality beyond the motion capture data.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">For example, we have generated a motion using constraints that cannot be satisfied directly by any motion in the database and found that the quality of the reconstructed motion was acceptable.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Unspecified">Our video also demonstrates that the system can generate motion for characters whose skeletal models differ significantly from those in the database.</DRI_Outcome> <DRI_FutureWork ann2="DRI_FutureWork" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_FutureWork">However, we have not yet attempted to assess how far the user’s constraints can stray from the motions in the database before the quality of the resulting animation declines to an unacceptable level.</DRI_FutureWork> <DRI_Outcome_Contribution ann2="DRI_FutureWork" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome_Contribution">This statistically based optimization approach complements a physically based optimization approach and offers a few potential advantages.</DRI_Outcome_Contribution> <DRI_Outcome_Contribution ann2="DRI_FutureWork" agreement="3diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome">First, using a low-dimensional statistical dynamic model for the constrained optimization might achieve faster convergence and be less subject to local minima.</DRI_Outcome_Contribution> <DRI_Outcome_Contribution ann2="DRI_FutureWork" agreement="3diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome">Second, our approach can generate slow and even stylized motions that have proven particularly difficult for physically based optimization.</DRI_Outcome_Contribution> <DRI_Outcome_Contribution ann2="DRI_FutureWork" agreement="3diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome">Third, the optimization does not require physical models.</DRI_Outcome_Contribution> <DRI_Outcome ann2="DRI_FutureWork" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Building anatomically accurate physical models for facial animation or whole-body motion remains challenging.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">There are two limitations of our approach: an appropriate database must be available and the user cannot specify such dynamic constraints as ground reaction forces or character mass.</DRI_Outcome> <DRI_Challenge_Goal ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Challenge_Goal" ann3="DRI_Challenge_Goal">The main focus of this paper has been an exploration of the use of prior knowledge in motion capture data to generate natural motion that best satisfies user-defined constraints.</DRI_Challenge_Goal> <DRI_Challenge ann2="DRI_Challenge" agreement="2equal_1diff" ann1="DRI_Challenge_Goal" ann3="DRI_Challenge">Another important issue for building any interactive animation system is to design an intuitive interface to specify the desired motion.</DRI_Challenge> <DRI_Approach agreement="All_Equal">In our experiments, most of keyframe constraints were modified from example poses in the database.</DRI_Approach> <DRI_Approach agreement="All_Equal">Foot contact constraints were specified by the user directly.</DRI_Approach> <DRI_Approach agreement="All_Equal">Key trajectory constraints were extracted from a performance interface using two video cameras [Chai and Hodgins 2005].</DRI_Approach> <DRI_Approach agreement="All_Equal">Alternatively, the user could rely on commercial animation software such as Maya to specify constraints.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Outcome">This process is timeconsuming even for a professional artist; it is more difficult for a naive user to specify such constraints.</DRI_Outcome> <DRI_FutureWork agreement="All_Equal">One of immediate directions for future work is, therefore, to design intuitive interfaces that allow the user to specify spatial-temporal constraints quickly and easily.</DRI_FutureWork>
      
      
        <h1>Acknowledgements</h1>
        <DRI_Unspecified agreement="All_Equal">The authors would like to thank Moshe Mahler for his help in modeling and rendering the images for this paper and Autodesk for the donation of Maya software.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">Partial support for this research was provided by NSF IIS-0326322.</DRI_Unspecified>
      
      
        <h1>References</h1>
        
          A BE , Y., L IU , C. K., AND P OPOVI Ć , Z. 2004. Momentumbased parameterization of dynamic character motion. In Proceedings of the 2004 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. 173–182.
          A RIKAN , O., AND F ORSYTH , D. A. 2002. Interactive motion generation from examples. In ACM Transactions on Graphics. 21(3):483–490.
          B AZARAA , M. S., S HERALI , H. D., AND S HETTY , C. 1993. Nonlinear Programming: Theory and Algorithms. John Wiley and Sons Ltd. 2nd Edition.
          B ISHOP , C. 1996. Neural Network for Pattern Recognition. Cambridge University Press.
          B RAND , M., AND H ERTZMANN , A. 2000. Style machines. In Proceedings of ACM ACM SIGGRAPH 2000. 183–192.
          B RAND , M. E. 1999. Voice puppetry. In Proceedings of ACM SIGGRAPH 1999. 21–28.
          B REGLER , C., C OVELL , M., AND S LANEY , M. 1997. Video rewrite: Driving visual speech with audio. In Proceedings of ACM SIGGRAPH 1997. 353-360.
          C HAI , J., AND H ODGINS , J. 2005. Performance animation from low-dimensional control signals. In ACM Transactions on Graphics. 24(3):686–696.
          C HAI , J., X IAO , J., AND H ODGINS , J. 2003. Vision-based control of 3d facial animation. In Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. 193-206.
          F ANG , A., AND P OLLARD , N. S. 2003. Efficient synthesis of physically valid human motion. In ACM Transactions on Graphics. 22(3):417–426.
          G ALATA , A., J OHNSON , N., AND H OGG , D. 2001. Learning variable length markov models of behavior. In Computer Vision and Image Understanding (CVIU) Journal. 81(3):398-413.
          G LEICHER , M. 1998. Retargeting motion to new characters. In Proceedings of ACM SIGGRAPH 1998. 33-42.
          G ROCHOW , K., M ARTIN , S. L., H ERTZMANN , A., AND P OPOVI C  ́ , Z. 2004. Style-based inverse kinematics. In ACM Transactions on Graphics. 23(3):522–531.
          G RZESZCZUK , R., T ERZOPOULOS , D., AND H INTON , G. 1998. Neuroanimator: Fast neural network emulation and control of physics-based models. In Proceedings of ACM SIGGRAPH 1998. 9-20.
          K OVAR , L., AND G LEICHER , M. 2004. Automated extraction and parameterization of motions in large data sets. In ACM Transactions on Graphics. 23(3):559–568.
          K OVAR , L., G LEICHER , M., AND P IGHIN , F. 2002. Motion graphs. In ACM Transactions on Graphics. 21(3):473–482.
          L EE , J., C HAI , J., R EITSMA , P., H ODGINS , J., AND P OLLARD , N. 2002. Interactive control of avatars animated with human motion data. In ACM Transactions on Graphics. 21(3):491–500.
          L I , Y., W ANG , T., AND S HUM , H.-Y. 2002. Motion texture: A two-level statistical model for character synthesis. In ACM Transactions on Graphics. 21(3):465–472.
          L IU , C. K., AND P OPOVI Ć , Z. 2002. Synthesis of complex dynamic character motion from simple animations. In ACM Transactions on Graphics. 21(3):408–416.
          L IU , K., H ERTZMANN , A., AND P OPOVI Ć , Z. 2005. Learning physics-based motion style with nonlinear inverse optimization. In ACM Transactions on Graphics. 23(3):1071–1081.
          L JUNG , L. 1999. System identification: Theory for the user. Prentice Hall PTR. 2nd Edition.
          M OLINA T ANCO , L., AND H ILTON , A. 2000. Realistic synthesis of novel human movements from a database of motion capture examples. In Proceedings of the Workshop on Human Motion. 137-142.
          M UKAI , T., AND K URIYAMA , S. 2005. Geostatistical motion interpolation. In ACM Transactions on Graphics. 24(3):1062– 1070.
          P ALM , W. J. 1999. Modeling, analysis, and control of dynamic systems. Wiley Publishers. 2nd Edition.
          P AVLOVI C  ́ , V., R EHG , J. M., AND M AC C ORMICK , J. 2000. Learning switching linear models of human motion. In Advances in Neural Information Processing Systems 13, 981–987.
          P OPOVI C  ́ , Z., AND W ITKIN , A. P. 1999. Physically based motion transformation. In Proceedings of ACM SIGGRAPH 1999. 1120.
          R OSE , C., C OHEN , M. F., AND B ODENHEIMER , B. 1998. Verbs and adverbs: Multidimensional motion interpolation. In IEEE Computer Graphics and Applications. 18(5):32–40.
          R OSE , C. F., S LOAN , P.-P. J., AND C OHEN , M. F. 2001. Artistdirected inverse-kinematics using radial basis function interpolation. In Computer Graphics Forum. 20(3):239-250.
          S AFONOVA , A., AND H ODGINS , J. K. 2007. Construction and optimal search of interpolated motion graphs. In ACM Transactions on Graphics. 26(3).
          S AFONOVA , A., H ODGINS , J., AND P OLLARD , N. 2004. Synthesizing physically realistic human motion in low-dimensional, behavior-specific spaces. In ACM Transactions on Graphics. 23(3):514–521.
          S OATTO , S., D ORETTO , G., AND W U , Y. N. 2001. Dynamic textures. In Proceedings of International Conference on Computer Vision (ICCV’01). 2:439–446.
          U RTASUN , R., F LEET , D. J., AND F UA , P. 2006. Temporal motion models for monocular and multiview 3d human body tracking. In Computer Vision and Image Understanding (CVIU). 104(2):157177.
          V ICON S YSTEMS , 2004. http://www.vicon.com .
          W ITKIN , A., AND K ASS , M. 1988. Spacetime constraints. In Proceedings of ACM SIGGRAPH 1998. 159–168.
          Z HANG , L., S NAVELY , N., C URLESS , B., AND S EITZ , S. M. 2004. Spacetime faces: high resolution capture for modeling and animation. In ACM Transactions on Graphics. 23(3):548–558.
        
      
    
  
</Document>