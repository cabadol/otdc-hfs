<?xml version="1.0" encoding="UTF-8" ?>
<Document corpusVersion="3" name="A14_M05_Example-Based_Control_of_Human_Motion">
  
    9bbec75829de844f588e58e42b0f60d4c7dac555be4c472c47ce8617992cd3f8
    3vtb
    http://dx.doi.org/10.1145/1028523.1028534
  
  
    
      Eurographics/ACM SIGGRAPH Symposium on Computer Animation (2004) R. Boulic, D. K. Pai (Editors)
      
        <article-title>Example-Based Control of Human Motion</article-title>
      
      <Sentence agreement="All_Equal">Eugene Hsu 1 Sommer Gentry
      1 Computer Science and Artificial Intelligence Laboratory 2 Laboratory for Information and Decision Systems Massachusetts Institute of Technology
      In human motion control applications, the mapping between a control specification and an appropriate target motion often defies an explicit encoding.</Sentence> <DRI_Outcome_Contribution ann2="DRI_Outcome_Contribution" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Challenge_Goal">We present a method that allows such a mapping to be defined by example, given that the control specification is recorded motion.</DRI_Outcome_Contribution> <DRI_Approach agreement="All_Equal">Our method begins by building a database of semantically meaningful instances of the mapping, each of which is represented by synchronized segments of control and target motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">A dynamic programming algorithm can then be used to interpret an input control specification in terms of mapping instances.</DRI_Approach> <DRI_Approach agreement="All_Equal">This interpretation induces a sequence of target segments from the database, which is concatenated to create the appropriate target motion.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">We evaluate our method on two examples of indirect control.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">In the first, we synthesize a walking human character that follows a sampled trajectory.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">In the second, we generate a synthetic partner for a dancer whose motion is acquired through motion capture.</DRI_Approach>
	  <h2>Categories and Subject Descriptors (according to ACM CCS): </h2>I.3.7 [Computer Graphics]: Animation
      
        
          Jovan Popović
        
      
    
    
      
        <h1>1. Introduction</h1>
      
      <DRI_Challenge agreement="All_Equal">Authoring human motion is difficult for computer animators, as humans are exceptionally sensitive to the slightest of errors.</DRI_Challenge> <DRI_Challenge ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">This process involves an animator providing a control specification which is mapped to a target motion by some means.</DRI_Challenge> <DRI_Background agreement="All_Equal">In traditional keyframe animation, for instance, the keyframes are the control specification, and the target motion is achieved through spline interpolation.</DRI_Background> <DRI_Background agreement="All_Equal">Due to advances in data acquisition technology and computational power, techniques have been developed that allow desired target motion to be specified using a human performance.</DRI_Background> <DRI_Background agreement="All_Equal">This is natural for traditional keyframe animators, who often use recorded or live human motion for reference.</DRI_Background> <DRI_Background agreement="All_Equal">Motion capture is the most direct method to map performances to animated humans, as it is essentially an identity mapping.</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Challenge_Goal">However, a generalization of this approach to allow for more indirect mappings creates an array of fantastic possibilities, such as mapping voice signals to facial motion [Bra99] or gestural actions to animated reactions [JP99].</DRI_Background> <DRI_Challenge ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">Indirect mappings, however, must still be encoded in some way.</DRI_Challenge> <DRI_Challenge agreement="All_Equal">Manually, this can be an exceptionally challenging task requiring detailed, domain-specific knowledge.</DRI_Challenge> <DRI_Challenge ann2="Sentence" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">Consider a partner dance scenario in which an animator wishes to con-
      trol a follower using the captured motion of a leader.</DRI_Challenge> <DRI_Challenge ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">The mapping from leader to follower motion must minimally encode a significant amount of knowledge about the structure of the dance; this knowledge, unfortunately, would be out of reach to an animator who is not a skilled dancer.</DRI_Challenge> <DRI_Challenge ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Challenge">Indeed, it would still be difficult for a skilled dancer to state the precise mapping.</DRI_Challenge> <DRI_Challenge_Goal agreement="All_Equal">Human dancers learn their skills by observation and practice; our objective is to emulate this process on a computer for situations, such as partner dance, when the control specification takes the form of one dancer’s motion.</DRI_Challenge_Goal> <DRI_Approach agreement="All_Equal">To learn indirect mappings, we adopt a memory-based approach which implicitly encodes the desired mapping using a database of semantically meaningful example instances.</DRI_Approach> <DRI_Approach agreement="All_Equal">These instances store segments of synchronized control and target motion, which provide examples of how the mapping should be applied to input control motions.</DRI_Approach> <DRI_Approach agreement="All_Equal">In partner dance, an instance might contain an example control motion of a leader pushing his or her partner forward.</DRI_Approach> <DRI_Approach agreement="All_Equal">The corresponding example target motion would be that of the follower, taking a step backward in response.</DRI_Approach> <DRI_Approach agreement="All_Equal">A new input control motion can be interpreted as a sequence of rigidly transformed and temporally stretched control segments from the mapping database.</DRI_Approach> <DRI_Approach agreement="All_Equal">Through the mapping instances, a given interpretation also corresponds to a sequence of target segments that can be assembled to form a target motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">We use dynamic programming to select a sequence that balances the quality of interpretation with the continuity of the induced target motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">Various postprocessing techniques can be then be applied to smooth and adjust the desired target motion.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Our approach is evaluated on two applications.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">In the first, we demonstrate its ability to map low-dimensional input to high-dimensional motion by controlling walk motion from mouse trajectories.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">In the second, we highlight our method’s capability to handle complex, stylized mappings by controlling a dance follower with the motion of a dance leader.</DRI_Outcome>
      c The Eurographics Association 2004.
      Hsu, Gentry, and Popović / Example-Based Control of Human Motion
      
        <h1>2. Background</h1>
        <DRI_Background agreement="All_Equal">Performance-driven animation, or computer puppetry, derives its broad appeal from its ability to map human performances automatically to animated characters [Stu98].</DRI_Background> <DRI_Background agreement="All_Equal">While these mappings can be as simple as a direct copy of joint angles, the ability to discover more complex mappings gives the approach a tremendous amount of power and flexibility.</DRI_Background> <DRI_Background agreement="All_Equal">In online techniques [JP99], computational speed and instantaneous results are of paramount importance; offline techniques [Bra99] allow quality and global optimality to take precedence.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Our method falls into the latter category.</DRI_Approach> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">Complex mappings often defy purely physical or mathematical encodings.</DRI_Background> <DRI_Background agreement="All_Equal">As a result, many methods assume that mappings are described by parametric probabilistic models [Bra99, DB01, DYP03, JP99].</DRI_Background> <DRI_Background agreement="All_Equal">An advantage of these techniques is their ability to generalize to a variety of inputs.</DRI_Background> <DRI_Challenge ann2="DRI_Challenge" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">However, this comes at a price: statistical learning often necessitates large volumes of training data or severe restrictions on model complexity.</DRI_Challenge> <DRI_Challenge ann2="DRI_Challenge" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Background">For certain applications, this is a worthwhile tradeoff, but for others, it can result in impractically long training times or loss of important detail.</DRI_Challenge> <DRI_Approach ann2="DRI_Outcome" agreement="3diff" ann1="DRI_Approach" ann3="DRI_Background">A memory-based approach like ours does not suffer from these disadvantages.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">An important benefit of this design choice is the ability to use segments, rather than frames, as the primitive unit of motion.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">This allows for explicit preservation of higherlevel motion semantics.</DRI_Approach> <DRI_Background agreement="All_Equal">Kim et al. demonstrate that a semantically guided segmentation of rhythmic motion allows for highly realistic motion synthesis, even using simple transition models [KPS03].</DRI_Background> <DRI_Background agreement="All_Equal">Although this work, like ours, uses partner dance for evaluation, it does not address the problem of generating a follower given the motion of a leader.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">In the segment modeling domain, we consider our method most similar to that of Pullen and Bregler [PB02].</DRI_Approach> <DRI_Background agreement="All_Equal">While Pullen and Bregler’s method was shown to be an effective solution for the chosen application of texturing keyframed motion, its applicability to our problem is limited by several factors.</DRI_Background> <DRI_Background agreement="All_Equal">First, their method assumes no spatial dependencies between the control (keyframed curves) and the target (textured motion).</DRI_Background> <DRI_Background agreement="All_Equal">Second, there is no enforcement of motion continuity, other than a heuristic for consecutively observed segments.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Our approach generates target motion segments that are amenable to simple blending.</DRI_Approach> <DRI_Background agreement="All_Equal">Finally, their method assumes that the input motion can be presegmented analogously to the examples, which is achieved in their work by observing sign changes in velocity.</DRI_Background> <DRI_Background ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Background">One could extend this approach for rhythmic motions using the automated approach of Kim et al. [ KPS03 ].</DRI_Background> <DRI_Challenge ann2="DRI_Approach" agreement="3diff" ann1="DRI_Challenge" ann3="DRI_Background">In the general case, however, a control motion may not admit any intuitive presegmentation.</DRI_Challenge> <DRI_Challenge ann2="DRI_Approach" agreement="3diff" ann1="DRI_Challenge" ann3="DRI_Background">One may wish, for instance, to generate walk motion from a constant-velocity trajectory.</DRI_Challenge> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Our method requires no presegmentation; moreover, it produces a semantically guided segmentation as part of the optimization.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">In this context, our algorithm could be viewed as an extension of speech recognition methods that use connected word models [ RJ93 ].</DRI_Approach> <DRI_Background agreement="All_Equal">Arikan et al. describe an example-based approach to synthesizing human motion that satisfies sparse temporal annotation and pose constraints [ AFO03 ].</DRI_Background> <DRI_Background agreement="All_Equal">Although their work differs from ours in intent, they also employ a dynamic programming algorithm that optimizes a weighted combination of interpretation and motion continuity.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Our formulation differs in two subtle but important ways.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">First, our notion of continuity is dependent on the interpretation; that is, the continuity between two motion segments is undefined until a candidate interpretation specifies a coordinate frame for comparison.</DRI_Approach> <DRI_Background agreement="All_Equal">Second, their objective function is defined over frames instead of segments.</DRI_Background> <DRI_Background agreement="All_Equal">As a result, they must use coarse-to-fine iterations of their dynamic programming algorithm to gain the temporal consistency that is intrinsic to our segment-based approach.</DRI_Background> <DRI_Background agreement="All_Equal">Other related methods based on motion capture clip rearrangement include work by Kovar et al. [ KGP02 ], Lee et al. [ LCR ∗ 02 ], and Arikan and Forsyth [ AF02 ].</DRI_Background> <DRI_Background agreement="All_Equal">Although these do not aim to discover control by example, they have nevertheless provided inspiration for our work.</DRI_Background> <DRI_Background agreement="All_Equal">An additional distinction is that these methods do not use continuous control from human performance and focus on sparser specifications such as keyframes and nontemporal paths.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Our method is not designed to handle such control specifications and therefore should be viewed as an alternative to these approaches, rather than a replacement.</DRI_Approach> <DRI_Background agreement="All_Equal">Many motion rearrangement techniques are derived from previous work in texture synthesis.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Here, we consider our work most similar in intent to image analogies [ HJO ∗ 01 ].</DRI_Approach> <DRI_Background agreement="All_Equal">This method, given an unfiltered and filtered version of the same image, applies an analogous filter to a novel image.</DRI_Background> <DRI_Approach agreement="All_Equal">Our method, given a set of synchronized control and target motions, applies an analogous mapping to a new input control motion.</DRI_Approach> <DRI_Background agreement="All_Equal">Image analogies was shown to be an elegant method with applications such as texture transfer, textureby-numbers, and super-resolution.</DRI_Background> <DRI_Challenge_Goal ann2="DRI_Challenge_Hypothesis" agreement="2equal_1diff" ann1="DRI_Challenge_Goal" ann3="DRI_Challenge_Goal">It is our hope that our method will have the same versatility for motion.</DRI_Challenge_Goal> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">Our dance evaluation suggests an alternative view of our method as one of interaction modeling.</DRI_Outcome> <DRI_Background agreement="All_Equal">In this domain, tech- niques have been developed that specify the mappings between character motions with explicit models of character interaction.</DRI_Background> <DRI_Background agreement="All_Equal">Adaptive autonomous characters have used rules to exhibit complex flocking, herding, and locomotory behaviors [Rey87, TT94].</DRI_Background> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Background">Approaches to explicit interaction modeling have included layered architectures [BG95], procedural descriptions [PG96], and even cognitive models [FTT99].</DRI_Background> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome">In this context, our work might be viewed as a competency module that enhances the skills of characters to enable their participation in complex interactive performances.</DRI_Outcome>
        c The Eurographics Association 2004.
        Hsu, Gentry, and Popović / Example-Based Control of Human Motion
        Control Target
        
          Figure 1: Segmentation of Lindy Hop motion into two-beat rhythm units.
        
      
      
        <h1>3. Database Construction</h1>
        <Sentence ann2="DRI_Approach" agreement="2equal_1diff" ann1="Sentence" ann3="Sentence">We begin by acquiring examples of synchronized control motions A and target motions B. Each frame of motion is encoded by a point cloud.</Sentence> <DRI_Approach agreement="All_Equal">For human motion, we use skeletal joint positions, since this representation provides a more intuitive space than joint angle representations for comparing poses [KGP02].</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Furthermore, point cloud representations allow for generalization to control motions without skeletal representations, such as mouse input.</DRI_Approach> <DRI_Approach agreement="All_Equal">The examples are divided into control segments a 1 , . . . , a N and target segments b 1 , . . . , b N , where a i and b i are synchronized motions that together represent a primitive semantic instance of the mapping.</DRI_Approach> <DRI_Approach agreement="All_Equal">Our dance motions are segmented into two-beat rhythm units, since they are a basic unit of interaction for the specific type of dance (Lindy Hop), as shown in Figure 1 .</DRI_Approach> <DRI_Approach agreement="All_Equal">Our walk motions, on the other hand, are segmented according to gait cycles.</DRI_Approach> <DRI_Approach agreement="All_Equal">In both cases, we use manual transcription, since each example motion must only be segmented once.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Approach">Methods exist to automate this process if desired.</DRI_Approach> <DRI_Approach agreement="All_Equal">Dance motion could be segmented using motion beat analysis [KPS03].</DRI_Approach> <DRI_Approach agreement="All_Equal">More general motions could be segmented using annotation [AFO03] or curve clustering [CGMS03].</DRI_Approach>
      
      
        <h1>4. Algorithm Description</h1>
        <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Challenge_Goal">Given a control motion x with T frames, our goal is to generate an appropriate target motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">This is achieved by selecting a sequence of appropriate target segments from the database.</DRI_Approach> <DRI_Approach agreement="All_Equal">To make the database motions more flexible, we allow each selected target segment to be spatially transformed and uniformly stretched in time.</DRI_Approach> <DRI_Approach agreement="All_Equal">The proper selection of segments can be achieved using an efficient dynamic programming algorithm.</DRI_Approach>
        
          Figure 2: An example instance from the database is stretched and transformed to align the control segment with the input motion. The same stretch and transform can then be applied to the target segment.
        
      
      
        <h1>4.1. Single Segment</h1>
        <DRI_Approach agreement="All_Equal">Before developing our general algorithm, we address the simpler problem of interpreting the input as a single control segment from the database.</DRI_Approach> <DRI_Approach agreement="All_Equal">We quantify the similarity of the input motion x and a control segment a s with a distance function:</DRI_Approach>
        
          1
          D(x, T s ) ≡ − s T )a s T 2 .
        
      
      
        <h1>a x M(x, a</h1>
        <DRI_Approach agreement="All_Equal">Here, a T s represents the control segment a s , uniformly stretched in time to T frames, and M(x, a s T ) is a rigid transformation that optimally aligns x and a s T :</DRI_Approach>
        
          2
          2
        
        
          2
          M(x, a s T ) ≡ arg min M x − Ma s T .
        
        <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">This optimization is the solution to the Procrustes problem, which has several efficient numerical solutions [ELF97].</DRI_Approach> <DRI_Approach agreement="All_Equal">Since our example dance and walk motions only differ by ground translation and vertical rotation, our implementation uses a closed form solution [KGP02].</DRI_Approach> <DRI_Approach agreement="All_Equal">To compute the optimal interpretation, we determine the segment a s ∗ that is most similar to the input motion:</DRI_Approach>
        
          3
          s ∗ = arg min s D(x, a T s ).
        
        <DRI_Approach agreement="All_Equal">The index s ∗ also identifies, by construction of the database, an appropriate target b s ∗ for both the control segment a s ∗ and the input motion x.</DRI_Approach> <DRI_Approach agreement="All_Equal">The stretch T completes the specification of the optimal interpretation, M(x, a T s ∗ )a T s ∗ , and the optimal target, M(x, a T s ∗ )b T s ∗ .</DRI_Approach> <DRI_Unspecified agreement="All_Equal">This is illustrated in Figure 2 .</DRI_Unspecified> <DRI_Approach agreement="All_Equal">The optimal target may not precisely satisfy desired physical or kinematic constraints.</DRI_Approach> <DRI_Approach agreement="All_Equal">However, given a descriptive database, it can provide a good approximation which can be adjusted appropriately during postprocessing.</DRI_Approach> <DRI_Approach agreement="All_Equal">In practice, we limit the allowed amount of uniform time stretch by a constant factor since the distance metric does not distinguish between motions of varying speed.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">A dancer that pushes his partner slowly, for instance, will elicit quite a different response if he pushes quickly.</DRI_Approach> <DRI_Approach agreement="All_Equal">Limiting the amount of stretch also has the practical benefit of reducing the search space of our general algorithm, which we will now describe.</DRI_Approach>
        c The Eurographics Association 2004.
        Hsu, Gentry, and Popović / Example-Based Control of Human Motion
        1 2 3 4 5 1 3 4 1 5 4
        
          Figure 3: A good interpretation may not account for the continuity of the target (middle). Our scoring function strikes a balance between the two (bottom).
        
      
      
        <h1>4.2. Multiple Segments</h1>
        <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Challenge" ann3="DRI_Approach">In general, we must handle the case where the optimal control and target consist of a sequence of segments.</DRI_Approach> <DRI_Approach agreement="All_Equal">We can specify this sequence analogously to the single segment case by the number of segments L ∗ , the segment indices s ∗ 1 , . . . , s ∗ L , and the segment durations d 1 ∗ , . . . , d L ∗ .</DRI_Approach> <DRI_Approach agreement="All_Equal">As in the single segment case, the distance metric D evaluates the interpretation quality of each segment in the sequence.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">However, the quality of the interpretation alone does not account for the continuity of the target motion, as shown in Figure 3 .</DRI_Approach> <DRI_Approach agreement="All_Equal">To offset this problem, we introduce a function which measures the continuity between segments v and w:</DRI_Approach>
        
          4
          C(v, w) = ω(v) − α(w) 2 .
        
        <DRI_Approach agreement="All_Equal">Here, α and ω represent the head and tail functions, which respectively extract the positions of the first and last frame of a segment.</DRI_Approach> <DRI_Approach agreement="All_Equal">One could also use more frames to measure higher-order continuity if desired.</DRI_Approach> <DRI_Approach agreement="All_Equal">Given a sequence specification L, s 1 , . . . , s L , and d 1 , . . . , d L , we define a scoring function that accounts for both the quality of interpretation and the continuity of the target:</DRI_Approach>
        
          5
          L L−1 ∑ D(x i , a s d i i ) + k ∑ C M i b s d i i , M i+1 b s d i+1 i+1 . i=1 i=1
        
        <DRI_Approach agreement="All_Equal">Here, x i is the subinterval of the input that is implied by the segment durations d 1 , . . . , d i .</DRI_Approach> <DRI_Approach agreement="All_Equal">These in turn induce the transformations M i ≡ M(x i , a d s i i ).</DRI_Approach> <DRI_Approach agreement="All_Equal">The user-specified constant k defines the balance of interpretation and continuity.</DRI_Approach> <DRI_Approach agreement="All_Equal">The optimal substructure property of the score function, as defined by the following recurrence, can be used to find a globally optimal solution using dynamic programming:</DRI_Approach>
        
          6
          Q s,d [t] = min r,c Q r,c [t − d] + D(x d,t , a s d )
        
        
          6
          a + kC(M r,c,t−d b r c , M s,d,t b d s )
        
        
          7
          Q s,d [d] = D(x d,d , a s d ).
        
        <DRI_Approach agreement="All_Equal">Here, x d,t represents the subsequence of input frames starting at frame t − d and ending at frame t, which in turn induces the alignment matrix M s,d,t ≡ M(x d,t , a d s ).</DRI_Approach> <DRI_Approach agreement="All_Equal">Q s,d [t] is defined as the score of the optimization on the subsequence x t,t , given that the last segment is indexed by s and stretched to duration d.</DRI_Approach> <DRI_Approach agreement="All_Equal">By minimizing Q s,d [T ] over all s and d, we can compute the score of the optimal sequence specification and recover it by backtracking.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">In the following section, we describe this process in more detail.</DRI_Unspecified>
      
      
        <h1>4.3. Implementation</h1>
        <DRI_Approach agreement="All_Equal">To solve the recurrence efficiently, values of Q are stored in a two-dimensional array.</DRI_Approach> <DRI_Approach agreement="All_Equal">Cells in this array are indexed by the time t on one axis and by all legal combinations of s and d on the other (recall from Section 4.1 that the amount of allowed stretch is limited).</DRI_Approach> <DRI_Approach agreement="All_Equal">First, all legal values of Q s,d [d] are initialized according to the base case given in Equation 7, and all other array cells are set to infinity.</DRI_Approach> <DRI_Approach agreement="All_Equal">The algorithm proceeds by iterating forward through time.</DRI_Approach> <DRI_Approach agreement="All_Equal">At each time t, all non-infinite cells are located and scores are conditionally propagated forward in time according to Equation 6.</DRI_Approach> <DRI_Approach agreement="All_Equal">More specifically, suppose that we are currently processing the array cell Q r,c [t].</DRI_Approach> <DRI_Approach agreement="All_Equal">For each legal combination of s and d, the candidate value z is computed:</DRI_Approach>
        
          8
          z = Q r,c [t] + D(x d,t+d , a s d ) + kC(M r,c,t b r c , M s,d,t+d b d s ).
        
        <DRI_Approach agreement="All_Equal">If the value in the array cell Q s,d [t + d] is greater than z, we set it to z and store a backpointer to cell Q r,c [t].</DRI_Approach> <DRI_Approach agreement="All_Equal">By continuing this process, the entire array is filled.</DRI_Approach> <DRI_Approach agreement="All_Equal">Since the indexing of each cell encodes a segment identifier and duration, the optimal sequence specification can be recovered by following backpointers from the best score at time T .</DRI_Approach>
      
      
        <h1>4.4. Efficiency</h1>
        <DRI_Approach agreement="All_Equal">At each time t, O(P) noninfinite cells are processed, where P is the number of legal combinations of s and d.</DRI_Approach> <DRI_Approach agreement="All_Equal">Since processing an individual cell is an O(P) operation, the total asymptotic time complexity of the algorithm is O(P 2 T ).</DRI_Approach> <DRI_Approach agreement="All_Equal">To increase its efficiency, we apply several heuristic optimizations.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Beam search.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">Rather than process all O(P) noninfinite cells at each time t, we only process cells with scores less than min s,d Q s,d [t] + w, where w is a user-specified constant.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">This technique is known as beam search, and w is known as the beam width.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">This is motivated by the fact that cells with worse scores are unlikely to be on the optimal backtracking path, and thus can be pruned from the search.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Clustering.</DRI_Unspecified> <DRI_Unspecified ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Unspecified" ann3="DRI_Unspecified">In Section 3, we described the construction of a motion database by storing all instances derived from the examples.</DRI_Unspecified> <DRI_Approach ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">Since the time complexity of the algorithm scales quadratically with the database size, this leads to inefficiency when the number of instances is large.</DRI_Approach> <DRI_Approach agreement="All_Equal">To resolve this issue, redundant instances are eliminated using complete-linkage clustering [DHS00].</DRI_Approach> <DRI_Approach agreement="All_Equal">For this, the distances between instances is defined by Equation 1.</DRI_Approach> <DRI_Approach ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">The advantage of complete-linkage clustering over other methods (such as k-means) is that it explicitly limits the distance of any two instances in a cluster by a user-defined threshold.</DRI_Approach> <DRI_Approach agreement="All_Equal">After clusters are formed, a representative instance is chosen at random from each cluster to remain in the database, and all other instances are discarded.</DRI_Approach> <DRI_Approach agreement="All_Equal">An additional benefit of this process is that it helps beam search; since clustering reduces ambiguity in interpretation, a larger proportion of search paths can be pruned.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Downsampling.</DRI_Unspecified> <DRI_Background agreement="All_Equal">High sampling rates are common for systems such as motion capture, but they are generally unnecessary for interpreting the input control motion.</DRI_Background> <DRI_Approach agreement="All_Equal">By downsampling motions by a user-chosen constant, we can effectively reduce the length of the input sequence.</DRI_Approach> <DRI_Approach ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Approach">However, the resulting optimal sequence specification will also be at the lower frame rate, and it is generally desirable to have it at the frame rate of the original input.</DRI_Approach> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Approach">Simple upsampling often introduces slight but undesirable temporal errors.</DRI_Background> <DRI_Approach agreement="All_Equal">To remedy this, we run a highly constrained version of our dynamic programming algorithm that only adjusts the durations appropriately.</DRI_Approach> <DRI_Approach agreement="All_Equal">Constraints can be easily encoded by making appropriate cells in the Q array illegal.</DRI_Approach> <DRI_Approach agreement="All_Equal">For instance, we can force the result to contain a certain target segment b s at some time t by disallowing any processing on cells Q r,c [u], where r = s and u − c ≤ t ≤ u.</DRI_Approach>
        c The Eurographics Association 2004.
        Hsu, Gentry, and Popović / Example-Based Control of Human Motion
      
      
        <h1>5. Postprocessing</h1>
        <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">As described in Section 4, the output of our optimization is a specification of an appropriate target motion in terms of target segments in a database.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Specifically, it provides a sequence of target segment indices s ∗ 1 , . . . , s L and durations d 1 ∗ , . . . , d L ∗ .</DRI_Outcome> <DRI_Approach agreement="All_Equal">The corresponding target segments can be copied from the database, stretched, transformed by the induced matrices M ∗ 1 , . . . , M ∗ L , and concatenated.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">The result is a moving point cloud that approximates the desired result.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">Of course, the same selections, stretches, and transformations can just as easily be applied to the source motions that generated the point cloud.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">From the perspective of motion synthesis, the main problem with our approach is that the raw result will generally contain some kinematic errors.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">In our dance example, footplant and handhold constraints are never explicitly enforced.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">For such constraints, existing methods can be applied to postprocess the data [KSG02], but such methods often require some amount of manual constraint annotation.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">Like similar motion clip rearrangement techniques, we can propagate constraints by example.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">In other words, each example instance can be annotated with constraints that can be transferred to the target motion.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">This is demonstrated by our propagation of handhold constraints, shown in Figure 4 .</DRI_Approach> <DRI_Challenge_Goal ann2="DRI_Challenge_Goal" agreement="2equal_1diff" ann1="DRI_Challenge_Goal" ann3="DRI_Approach">We do not aim to introduce novel solutions for motion blending or constraint satisfaction.</DRI_Challenge_Goal> <DRI_Challenge_Goal agreement="All_Equal">Instead, our goal is to provide motion that is amenable to postprocessing with these approaches.</DRI_Challenge_Goal> <DRI_Outcome agreement="All_Equal">To demonstrate our method’s capabilities in this regard, we show that it can generate realistic and compelling motion, even with extremely simple postprocessing.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">Our results, shown in the following section and in our accompanying video, are filtered with a basic smoothing operation that linearly adjusts motion curves to match across segment boundaries.</DRI_Outcome>
        
          
          Figure 4: A handhold constraint, indicated by the line connecting the characters, is propagated from annotated examples to this generated motion. In this two-beat sequence, the leader begins in an open crosshand stance and pulls the follower in (1,2). The follower releases handhold and performs an inside turn toward the leader (3,4). Nearing completion of the turn, the follower prepares to catch the leader’s hand and enter embrace (5), and handhold is reestablished in closed stance (6).
        
      
      
        <h1>6. Results and Evaluation</h1>
        <DRI_Approach agreement="All_Equal">We evaluate our technique with two examples.</DRI_Approach> <DRI_Approach agreement="All_Equal">In the first, we animate a realistic walking human from time-sampled mouse movement.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Walk motions, however, do not show the full ability of our technique to discover complex mappings.</DRI_Approach> <DRI_Approach agreement="All_Equal">To better demonstrate this aspect, we apply our method to a partner dance called Lindy Hop.</DRI_Approach> <DRI_Approach agreement="All_Equal">Specifically, we use the complex motion of the dance leader to drive the motion of the follower.</DRI_Approach> <DRI_Approach agreement="All_Equal">In the following sections, all human motions were acquired in a motion capture studio and standard commercial tools were used to estimate joint positions [Vic03].</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">For the point cloud representation of body motion, we used only the positions of the hands and feet, as we found that these endeffectors were sufficient to evaluate interpretation and continuity in both evaluations.</DRI_Approach> <DRI_Approach agreement="All_Equal">To generate the motion, we applied the resulting sequence specification to the source motion and used basic smoothing.</DRI_Approach> <DRI_Approach agreement="All_Equal">All timings were performed on a workstation with dual 2.4 Ghz Intel Xeon processors.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Unspecified">Where applicable, we state the clock times for the dynamic programming algorithm (Section 4.3), upsampling (Section 4.4), and postprocessing (Section 5).</DRI_Approach> <DRI_Approach agreement="All_Equal">The continuity constant, defined in Section 4.2, and the stretch limit were chosen experimentally.</DRI_Approach>
        c The Eurographics Association 2004.
        Hsu, Gentry, and Popović / Example-Based Control of Human Motion
      
      
        <h1>6.1. Walk</h1>
        <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">We acquired 2 minutes of motion captured walk footage at 30 Hz.</DRI_Approach> <DRI_Approach agreement="All_Equal">The subject was directed to walk within the capture area with random changes in direction and speed.</DRI_Approach> <DRI_Approach agreement="All_Equal">We artificially constructed a synchronized example control motion by projecting the positions of the hip joints onto the floor and normalizing their distance.</DRI_Approach> <DRI_Approach agreement="All_Equal">As stated previously, the target motions were represented by end-effector positions.</DRI_Approach> <DRI_Approach agreement="All_Equal">The walk footage was transcribed manually according to the gait cycle.</DRI_Approach> <DRI_Approach agreement="All_Equal">More specifically, a segmentation point was manually placed at each footplant.</DRI_Approach> <DRI_Approach agreement="All_Equal">From this process, we created 200 segments, which we reduced to 70 using clustering.</DRI_Approach> <DRI_Approach agreement="All_Equal">In our tests, we downsampled these motions to 10 Hz and allowed each segment to be stretched ±0.2 seconds.</DRI_Approach> <DRI_Approach agreement="All_Equal">Our first evaluation involved creating control motions from new walk motions that were not in the database.</DRI_Approach> <DRI_Approach agreement="All_Equal">As before, we projected the hip joints onto the ground and normalized their distance.</DRI_Approach> <DRI_Approach agreement="All_Equal">We ran our algorithm on these control motions and compared our results to the original source motions.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Experimentally, we found that larger values of the continuity constant were more effective.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">For short walks, the generated motion was highly realistic.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">The frequency of the generated gait cycle nearly matched the frequency of the source, but phase differed.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">In more concrete terms, the generated motion might choose to start on the left foot, whereas the original source motion might start on the right.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">This was expected, as the control signals did not encode any phase information.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">For longer walks, however, we were surprised to discover that the generated motions often kept in nearly perfect phase with the source.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">The reason for this was that the subject preferred to make sharp turns with the same footwork pattern.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">These served as synchronizing signals which were propagated throughout the generated gait cycle due to the global optimization.</DRI_Outcome> <DRI_Approach agreement="All_Equal">In our timing tests, we used a 57 second control motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">We first ran the algorithm without the beam search optimiza- tion.</DRI_Approach> <DRI_Outcome agreement="All_Equal">The dynamic programming algorithm took 12.5 seconds, upsampling from 10 Hz to 30 Hz took 0.4 seconds, and postprocessing took 1.1 seconds.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">With the beam search optimization on, we were able to reduce the clock time of the algorithm to 1.2 seconds (47 seconds of input processed per second of clock time) while retaining visually perfect results.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">The upsampling and postprocessing times remained the same.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">We ran the algorithm on shorter and longer inputs and experimentally confirmed the asymptotic linear dependency of running time on input length, described in Section 4.4.</DRI_Approach> <DRI_Approach agreement="All_Equal">In our second evaluation, we built an interface that allowed users to draw paths using mouse input, as shown in Figure 5 .</DRI_Approach> <DRI_Approach agreement="All_Equal">The position of the mouse pointer was sampled at 30 Hz, and Frenet frames were used to generate a control motion.</DRI_Approach> <DRI_Outcome agreement="All_Equal">For a wide variety of user inputs, our method was capable of generating highly realistic walking motion.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Since the timing of the path was important, we found that users required minor training to understand the concept of performing a path instead of drawing it.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">It was often tempting, for instance, to rapidly move the mouse to draw a straight line.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">This would correspond to a impossibly fast run, well beyond the capabilities of a human.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">To resolve these issues, our interface allows a user to overlay the playback of an existing motion on the drawing canvas to get a sense of speed.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">Furthermore, it provides options to smooth the trajectory spatially and temporally.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">The speed of the algorithm allows for rapid feedback.</DRI_Outcome>
        
          
          Figure 5: A synthetic character walks along a trajectory from mouse input. The spacing of the points indicates the speed.
        
      
      
        <h1>6.2. Dance</h1>
        <DRI_Approach agreement="All_Equal">Our choice of partner dance as a demonstration was primarily motivated by the complexity of its style and mappings.</DRI_Approach> <DRI_Approach agreement="All_Equal">From a small segmented set of example instances, we generate a follower’s motion to accompany a leader’s motion.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Challenge">Generating partner dance motion would be a difficult trial for both physical methods, which would yield underdetermined systems, and statistical methods, which would typically require a very large database in place of our small segmented one.</DRI_Approach> <DRI_Approach agreement="All_Equal">Swing dance also allows for a more principled evaluation of our results than most types of motion, since the performance of the algorithm at generating valid mappings can be evaluated independently of style considerations or subjective judgments of motion quality.</DRI_Approach> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Lindy Hop is a subgenre of swing dance that, at a basic level, can be described as a state machine.</DRI_Background> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">A dance couple moves between four basic stances: open (◦), closed (•), open crosshand (◦), and closed crosshand (•).</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Open and closed refer to whether the couple is apart or in embrace, respectively.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Crosshand refers to the case when the leader and follower hold right hands (we could also refer to it as a handshake).</DRI_Approach> <DRI_Approach agreement="All_Equal">Basic Lindy Hop motions switch between these four stances by means of transitions: an inside turn ( ), when the follower spins towards the leader, an outside turn ( ), when the follower spins away from the leader, and a simple step (→).</DRI_Approach> <DRI_Approach agreement="All_Equal">At the end of each transition, the dancers may also change their handhold to instantly transition between crosshand states (◦, •) and non-crosshand states (◦, •).</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Figure 4 shows a couple transitioning from open crosshand stance to closed stance using an outside turn: ◦ •.</DRI_Unspecified> <DRI_Approach agreement="All_Equal">Each of these transitions occurs over four beats of music, which are assembled from two-beat segments; this was our motivation for performing two-beat segmentation, as described in Section 3.</DRI_Approach> <DRI_Unspecified agreement="All_Equal">Figure 4 shows only the last two beats of a four-beat transition that starts with a two-beat rocking motion.</DRI_Unspecified> <DRI_Background ann2="DRI_Background" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Background">Skilled Lindy Hop dancers use a greater variety of moves, ranging from more complex transitions such as double outside turns to complex aerial maneuvers.</DRI_Background> <DRI_Approach agreement="All_Equal">We did not include the entire range of motions.</DRI_Approach> <DRI_Approach agreement="All_Equal">Instead, we constructed a smaller database with seven basic 8-beat dance patterns that every Lindy Hop dancer knows (shown in the first column of Table 1 ).</DRI_Approach> <DRI_Approach agreement="All_Equal">We constructed the motion database from a set of 12 short dances, each containing the seven basic 8-beat patterns, giving a total of 5 minutes of motion.</DRI_Approach> <DRI_Approach agreement="All_Equal">These dances were segmented into 364 two-beat mapping instances, with lengths varying from approximately 0.6 seconds to 1 second due to different music.</DRI_Approach> <DRI_Approach agreement="All_Equal">For our evaluations, we captured three longer test dances (approximately 2-3 minutes each) in which the dancers were instructed to improvise with the transitions and stances included in the database.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">Their improvisations led to dances which included thirteen new 8-beat patterns not found in the database (shown in the last column of Table 1 ) as well as some repeats of patterns in the database.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">These test dances spanned a tempo range from about 120 beats per minute to about 190 beats per minute.</DRI_Approach> <DRI_Approach agreement="All_Equal">We used the motion of the leader to control a synthetic follower, which was then compared with the actual follower.</DRI_Approach> <DRI_Outcome agreement="All_Equal">Visually, the results exhibited the fluidity, grace, and style of the original dancer.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Some footskate and handhold violations are visible because we wanted to show the output in its almost raw form, with smoothing applied only for visual coherence.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">In a direct comparison with the actual follower motions, we found that the synthetic follower matched very well in closed stances.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">In open stances, the follower was much freer to include stylistic variations, so the generated motions often differed visually from the actual motions.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Additionally, the synthesized dancers almost always kept in perfect rhythm with the leader.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Our algorithm ably recreated the semantics of the leader to follower mapping, even for novel patterns.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">When the algorithm encountered a pattern that was not in the database (one of 14 such patterns shown in Table 1 ), it was able to correctly reconstruct the novel sequence by rearranging the two-beat segments.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Of the 91 patterns (21 unique) in our three test dances, the synthetic dancer matched the pattern of the actual dancer in all but 5 cases, one of which is shown in Figure 6.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">When the algorithm did differ from the real dancer in the composition of the pattern, the leader and follower still executed a valid Lindy Hop pattern.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">In these misinterpreted instances, the leader’s motion is quite similar across two different follower patterns.</DRI_Outcome> <DRI_Outcome ann2="DRI_FutureWork" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Approach">To disambiguate these, we might add information to the control signal, such as forceplate readings, or we might accept these rare mismatches because they are in fact valid mappings.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Furthermore, all 5 mismatched patterns differed by a single two-beat segment, so, of 91 × 4 = 364 two-beat segments in the test dances, the algorithm misinterpreted the signal in 5 cases for an error rate of less than 2%.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Approach" ann3="DRI_Outcome">For all our evaluations and timing tests, we reduced the size of the database from 364 to 168 with clustering, downsampled to 7.5 Hz, and allowed a segment stretch of ±0.15 seconds.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">We cite our efficiency figures for generating, from leader motion only, a particular 150 second dance motion.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">Without beam search, the dynamic programming algorithm ran for 78 seconds, 2 seconds were spent on upsampling, and 26 seconds were spent on postprocessing.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">With beam search enabled with modest parameters, we were able to drive the runtime of the dynamic programming to 10 seconds while maintaining excellent visual and semantic results.</DRI_Outcome> <DRI_Outcome agreement="All_Equal">As with our walk motion evaluation, we found that clock times scaled linearly with the length of the input.</DRI_Outcome>
        c The Eurographics Association 2004.
        Hsu, Gentry, and Popović / Example-Based Control of Human Motion
        
          
            
              
                
                   Database Patterns
                   Test Patterns
                  
                
                
                   1 ◦→•→◦
                   1 ◦→• ◦
                   8 ◦ •→•
                
              
              
                
                   2 ◦→• ◦
                   2 •→• ◦
                   9 ◦ • ◦
                
                
                   3 ◦→•→•
                   3 •→•→•
                   10 ◦ •→◦
                
                
                   4 ◦→• ◦
                   4 •→• ◦
                   11 ◦→• ◦
                
                
                   5 ◦→• ◦
                   5 •→• ◦
                   12 ◦ • ◦
                
                
                   6 •→•→◦
                   6 •→•→◦
                   13 ◦ • ◦
                
                
                   7 ◦ •→◦
                   7 •→• ◦
                   14 ◦→•→◦
                
              
            
          
          Database Patterns Test Patterns 1 ◦→•→◦ 1 ◦→• ◦ 8 ◦ •→• 2 ◦→• ◦ 2 •→• ◦ 9 ◦ • ◦ 3 ◦→•→• 3 •→•→• 10 ◦ •→◦ 4 ◦→• ◦ 4 •→• ◦ 11 ◦→• ◦ 5 ◦→• ◦ 5 •→• ◦ 12 ◦ • ◦ 6 •→•→◦ 6 •→•→◦ 13 ◦ • ◦ 7 ◦ •→◦ 7 •→• ◦ 14 ◦→•→◦
          Table 1: A notational description of the dance patterns stored in the database and the novel test patterns performed in our three test dances. Our technique adapts by rearranging the segments in the database to recreate the patterns it has not seen before.
        
        c The Eurographics Association 2004.
        Hsu, Gentry, and Popović / Example-Based Control of Human Motion
        
          
          Figure 6: On the top, a clip of an actual dance is displayed. Here, the leader performs a regular handhold change during a step transition. This transition never occurs in our motion database. In response to the same motion cue, our algorithm generates a leaping outside turn, as show on the bottom. This is one of five two-beat segments (out of 380 two-beat segments in our three test dances), where the algorithm differs in its selection of response from an experienced dance follower. In other instances of this regular handhold change during a step transition in the test data, the algorithm correctly sequences motions to discover this novel vocabulary element.
        
      
      
        <h1>7. Conclusion</h1>
        <DRI_Outcome ann2="DRI_Outcome_Contribution" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">We have presented a method for example-based performance control of human motion.</DRI_Outcome> <DRI_Approach agreement="All_Equal">Our dynamic programming algorithm uses segments of motion along with an objective function that accounts for both the quality of control interpretation and the continuity of the target motion to generate visually and semantically correct motions.</DRI_Approach> <DRI_Approach agreement="All_Equal">The semantic accuracy of the generated motion was evaluated in the setting of partner dance, where the follower’s motion is generated from the leader’s motion.</DRI_Approach> <DRI_Outcome agreement="All_Equal">The algorithm generated semantically correct partner motion even from test sequences of leader motions that did not appear in the training set.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Our dynamic programming algorithm performs a global optimization, which precludes the local decisions that are required for online applications.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome">However, we demonstrate in our evaluations that it can compute results significantly faster than input motion can be recorded, thus making it suitable for rapid-feedback motion authoring applications.</DRI_Outcome> <DRI_Outcome_Contribution ann2="DRI_Outcome" agreement="3diff" ann1="DRI_Outcome_Contribution" ann3="DRI_FutureWork">We believe that segmental approaches like ours hold great promise for real-time performance-driven animation, and consider it a promising area of future research.</DRI_Outcome_Contribution> <DRI_Approach agreement="All_Equal">To preserve spatial dependencies in mappings, we apply rigid transformations to optimally align control segments with input control motions.</DRI_Approach> <DRI_Outcome ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome">Target segments inherit these transformations.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">This approach is effective for our applications or whenever the control signal indicates appropriate spatial and temporal cues.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">It is also possible to select other transformations for applications outside the domain of human motion control.</DRI_Outcome> <DRI_Outcome_Contribution ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome_Contribution" ann3="DRI_Outcome_Contribution">For instance, allowing arbitrary homogeneous transformations in two dimensions might form an alternative segmental solution to the curve analogies prob- lem [HOCS02].</DRI_Outcome_Contribution> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">Eliminating transformations entirely might also be appropriate for applications such as synthesis of facial motion from speech signals [Bra99].</DRI_Outcome> <DRI_Outcome agreement="All_Equal">We have shown that our segment similarity metric is effective for our experiments.</DRI_Outcome> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_FutureWork" ann3="DRI_Outcome">However, we acknowledge the fact that other metrics may be more appropriate for different types of motion and believe that it is a promising direction for future research.</DRI_Outcome> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">In the process of generating target motion, our dynamic programming algorithm performs a semantically guided segmentation of the input control motion.</DRI_Approach> <DRI_Approach ann2="DRI_Approach" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Approach">The entire process, however, relies on the availability of semantically segmented examples.</DRI_Approach> <DRI_Approach agreement="All_Equal">For our evaluations, we were able to perform this segmentation manually by tapping a key in response to the rhythm of music or the gait pattern of a walk cycle.</DRI_Approach> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Challenge_Goal">While specific methods exist to automate this segmentation for the cases of dance and walk, a more general method is desirable.</DRI_Outcome> <DRI_Outcome ann2="DRI_FutureWork" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Approach">For this, we could begin with a few manually segmented examples and grow the set of example instances by iterative application of our algorithm.</DRI_Outcome> <DRI_Background ann2="DRI_FutureWork" agreement="2equal_1diff" ann1="DRI_Background" ann3="DRI_Background">This approach would be similar in spirit to the semiautomatic SVM-based annotation approach of Arikan et al. [AFO03].</DRI_Background> <DRI_Outcome ann2="DRI_Outcome" agreement="2equal_1diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">The annotation propagation we describe above suggests that our method could be used for interpretation rather than control.</DRI_Outcome> <DRI_Outcome ann2="DRI_Approach" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">Paralleling our automatic annotation of handholds, it is possible to annotate any new control motion given a set of labeled example instances.</DRI_Outcome> <DRI_Outcome ann2="DRI_FutureWork" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">This could be used to transcribe the motion into a symbolic representation, such as the one used in this paper, or even Laban notation [Hut73].</DRI_Outcome> <DRI_Outcome ann2="DRI_FutureWork" agreement="3diff" ann1="DRI_Outcome" ann3="DRI_Outcome_Contribution">Such a representation could then be analyzed or summarized using natural language processing techniques.</DRI_Outcome>
        c The Eurographics Association 2004.
        Hsu, Gentry, and Popović / Example-Based Control of Human Motion
      
      
        <h1>Acknowledgments</h1>
        <DRI_Unspecified agreement="All_Equal">We would like to thank Jonathan Chu, Jim Glass, Kevin Murphy, the members of the MIT CSAIL graphics group, and the anonymous reviewers for their advice and assistance.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">Our dance evaluations would not have been possible without the generous help of Marilee Annereau, Bethany Certa, Rebecca Drzewiczewski, Steve Drzewiczewski, Amanda Gruhl, Shawn Hershey, Reuben Pharms, Paolo Piselli, Dorry Segev, Peter Strom, and Gary Ulaner.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">Funding for this work was provided by the MIT Oxygen Project.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">Eugene Hsu was partially supported by an MIT Presidential Fellowship.</DRI_Unspecified> <DRI_Unspecified agreement="All_Equal">Sommer Gentry was supported by a Department of Energy Computational Science Graduate Fellowship.</DRI_Unspecified>
      
      
        <h1>References</h1>
        
          [AF02] A RIKAN O., F ORSYTH D. A.: Interactive motion generation from examples. ACM Transactions on Graphics 21, 3 (July 2002), 483–490. 2
          [AFO03] A RIKAN O., F ORSYTH D. A., O’B RIEN J. F.: Motion synthesis from annotations. ACM Transactions on Graphics 22, 3 (July 2003), 402–408. 2, 3, 8
          [BG95] B LUMBERG B. M., G ALYEAN T. A.: Multi-level direction of autonomous creatures for real-time virtual environments. In Computer Graphics (Proceedings of SIGGRAPH 95) (Aug. 1995), Annual Conference Series, ACM SIGGRAPH, pp. 47–54. 3
          [Bra99] B RAND M.: Voice puppetry. In Proceedings of SIGGRAPH 99 (Aug. 1999), Computer Graphics Proceedings, Annual Conference Series, pp. 21–28. 1, 2, 8
          [CGMS03] C HUDOVA D., G AFFNEY S., M JOLSNESS E., S MYTH P.: Translation-invariant mixture models for curve clustering. In Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining (2003), ACM Press, pp. 79–88. 3
          [DB01] D E LA T ORRE F., B LACK M.: Dynamic coupled component analysis. Computer Vision and Pattern Recognition (2001), 643–650. 2
          [DHS00] D UDA R. O., H ART P. E., S TORK D. G.: Pattern Classification, second ed. John Wily &amp; Sons, Inc., New York, 2000. 5
          [DYP03] D ONTCHEVA M., Y NGVE G., P OPOVI C  ́ Z.: Layered acting for character animation. ACM Transactions on Graphics 22, 3 (July 2003), 409–416. 2
          [ELF97] E GGERT D. W., L ORUSSO A., F ISHER R. B.: Estimating 3-d rigid body transformations: a comparison of four major algorithms. Machine Vision and Applications 9 (1997), 272–290. 3
          [FTT99] F UNGE J., T U X., T ERZOPOULOS D.: Cognitive modeling: Knowledge, reasoning and planning for intelligent characters. In Proceedings of SIGGRAPH 99 (Aug. 1999), Computer Graphics Proceedings, Annual Conference Series, pp. 29–38. 3
          [HJO ∗ 01] H ERTZMANN A., J ACOBS C. E., O LIVER N., C UR LESS B., S ALESIN D. H.: Image analogies. In Proceedings of ACM SIGGRAPH 2001 (Aug. 2001), Computer Graphics Proceedings, Annual Conference Series, pp. 327–340. 2
          [HOCS02] H ERTZMANN A., O LIVER N., C URLESS B., S EITZ S. M.: Curve analogies. In Rendering Techniques 2002: 13th Eurographics Workshop on Rendering (June 2002), pp. 233–246. 8
          [Hut73] H UTCHINSON A.: Labanotation: The System of Analyzing and Recording Movement, third ed. Routledge, New York, 1973. 8
          [JP99] J EBARA T., P ENTLAND A.: Action reaction learning: Automatic visual analysis and synthesis of interactive behaviour. In ICVS (1999), pp. 273–292. 1, 2
          [KGP02] K OVAR L., G LEICHER M., P IGHIN F.: Motion graphs. ACM Transactions on Graphics 21, 3 (July 2002), 473– 482. 2, 3
          [KPS03] K IM T., P ARK S., S HIN S.: Rhythmic-motion synthesis based on motion-beat analysis. ACM Transactions on Graphics 22, 3 (July 2003), 392–401. 2, 3
          [KSG02] K OVAR L., S CHREINER J., G LEICHER M.: Footskate cleanup for motion capture editing. In ACM SIGGRAPH Symposium on Computer Animation (July 2002), pp. 97–104. 5
          [LCR ∗ 02] L EE J., C HAI J., R EITSMA P. S. A., H ODGINS J. K., P OLLARD N. S.: Interactive control of avatars animated with human motion data. ACM Transactions on Graphics 21, 3 (July 2002), 491–500. 2
          [PB02] P ULLEN K., B REGLER C.: Motion capture assisted animation: Texturing and synthesis. ACM Transactions on Graphics 21, 3 (July 2002), 501–508. 2
          [PG96] P ERLIN K., G OLDBERG A.: Improv: A system for scripting interactive actors in virtual worlds. In Computer Graphics (Proceedings of SIGGRAPH 96) (Aug. 1996), Annual Conference Series, ACM SIGGRAPH, pp. 205–216. 3
          [Rey87] R EYNOLDS C. W.: Flocks, herds, and schools: A distributed behavioral model. In Computer Graphics (Proceedings of SIGGRAPH 87) (July 1987), vol. 21, pp. 25–34. 3
          [RJ93] R ABINER L., J UANG B.-H.: Fundamentals of Speech Recognition. Prentice Hall, New Jersey, 1993. 2
          [Stu98] S TURMAN D. J.: Computer puppetry. IEEE Computer Graphics and Applications 18, 1 (1998), 38–45. 2
          [TT94] T U X., T ERZOPOULOS D.: Artificial fishes: Physics, locomotion, perception, behavior. In Proceedings of SIGGRAPH 94 (July 1994), Computer Graphics Proceedings, Annual Conference Series, pp. 43–50. 3
          [Vic03] V ICON : Vicon iQ Reference Manual. Vicon Motion Systems Inc., Lake Forest, CA, 2003. 6
        
        c The Eurographics Association 2004.
      
    
  
</Document>